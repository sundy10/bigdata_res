{"children":[{"children":[],"endTime":"2024-04-10 23:00:49.701","key":"b59628f3-75fd-41da-8ae8-72591e57dc54","log":"Start Process Step:SUBMIT_PRECHECK\n2024-04-10 23:00:49.700 INFO  org.dinky.service.impl.TaskServiceImpl(177): Start check and config task, task:KafkaReader\nProcess Step SUBMIT_PRECHECK exit with status:FINISHED\n","startTime":"2024-04-10 23:00:49.675","status":"FINISHED","time":26,"title":"检查作业","type":"SUBMIT_PRECHECK"},{"children":[{"children":[],"endTime":"2024-04-10 23:00:49.754","key":"b61cde53-efd1-478a-a882-6ad6fb5d1334","log":"Start Process Step:SUBMIT_BUILD_CONFIG\n2024-04-10 23:00:49.710 INFO  org.dinky.service.impl.TaskServiceImpl(286): Start initialize FlinkSQLEnv:\n2024-04-10 23:00:49.712 INFO  org.dinky.service.impl.TaskServiceImpl(306): Initializing data permissions...\n2024-04-10 23:00:49.730 INFO  org.dinky.service.impl.TaskServiceImpl(308): Finish initialize FlinkSQLEnv.\n2024-04-10 23:00:49.752 INFO  org.dinky.service.impl.TaskServiceImpl(236): Init remote cluster\nProcess Step SUBMIT_BUILD_CONFIG exit with status:FINISHED\n","startTime":"2024-04-10 23:00:49.709","status":"FINISHED","time":45,"title":"构建配置信息","type":"SUBMIT_BUILD_CONFIG"}],"endTime":"2024-04-10 23:01:26.094","key":"5fe00de0-2ecd-4c0d-be76-7357b68ee226","log":"Start Process Step:SUBMIT_EXECUTE\n2024-04-10 23:00:49.887 INFO  org.dinky.service.task.FlinkSqlTask(67): Initializing Flink job config...\n2024-04-10 23:00:49.917 INFO  org.dinky.job.builder.JobUDFBuilder(115): A total of 0 UDF have been Init.\n2024-04-10 23:00:49.919 INFO  org.dinky.job.builder.JobUDFBuilder(116): Initializing Flink UDF...Finish\n2024-04-10 23:00:49.921 INFO  org.dinky.utils.KerberosUtil(58): Simple authentication mode\n2024-04-10 23:00:49.930 INFO  org.dinky.utils.KerberosUtil(58): Simple authentication mode\n2024-04-10 23:00:50.130 INFO  org.apache.flink.configuration.Configuration(865): Config uses fallback configuration key 'rest.port' instead of key 'rest.bind-port'\n2024-04-10 23:00:50.132 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils(281): The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.\n2024-04-10 23:00:50.133 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils(281): The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.\n2024-04-10 23:00:50.134 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils(281): The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.\n2024-04-10 23:00:50.134 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils(281): The configuration option taskmanager.memory.network.min required for local execution is not set, setting it to its default value 64 mb.\n2024-04-10 23:00:50.136 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils(281): The configuration option taskmanager.memory.network.max required for local execution is not set, setting it to its default value 64 mb.\n2024-04-10 23:00:50.138 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils(281): The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.\n2024-04-10 23:00:50.140 INFO  org.apache.flink.runtime.minicluster.MiniCluster(322): Starting Flink Mini Cluster\n2024-04-10 23:00:50.662 INFO  org.apache.flink.runtime.minicluster.MiniCluster(341): Starting Metrics Registry\n2024-04-10 23:01:10.398 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl(142): No metrics reporter configured, no metrics will be exposed/reported.\n2024-04-10 23:01:10.399 INFO  org.apache.flink.runtime.minicluster.MiniCluster(348): Starting RPC Service(s)\n2024-04-10 23:01:10.429 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils(225): Trying to start local actor system\n2024-04-10 23:01:11.676 INFO  org.apache.pekko.event.slf4j.Slf4jLogger(117): Slf4jLogger started\n2024-04-10 23:01:12.055 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils(255): Actor system started at pekko://flink\n2024-04-10 23:01:12.081 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils(225): Trying to start local actor system\n2024-04-10 23:01:12.112 INFO  org.apache.pekko.event.slf4j.Slf4jLogger(117): Slf4jLogger started\n2024-04-10 23:01:12.136 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils(255): Actor system started at pekko://flink-metrics\n2024-04-10 23:01:12.225 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService(271): Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at pekko://flink-metrics/user/rpc/MetricQueryService .\n2024-04-10 23:01:12.249 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(127): Loading delegation token providers\n2024-04-10 23:01:12.254 WARN  org.apache.flink.runtime.util.HadoopUtils(139): Could not find Hadoop configuration via any of the supported methods (Flink configuration, environment variables).\n2024-04-10 23:01:12.256 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(135): Delegation token provider hadoopfs loaded and initialized\n2024-04-10 23:01:12.258 WARN  org.apache.flink.runtime.util.HadoopUtils(139): Could not find Hadoop configuration via any of the supported methods (Flink configuration, environment variables).\n2024-04-10 23:01:12.259 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(135): Delegation token provider hbase loaded and initialized\n2024-04-10 23:01:12.260 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(165): Delegation token providers loaded successfully\n2024-04-10 23:01:12.261 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository(64): Loading delegation token receivers\n2024-04-10 23:01:12.263 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository(72): Delegation token receiver hadoopfs loaded and initialized\n2024-04-10 23:01:12.264 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository(72): Delegation token receiver hbase loaded and initialized\n2024-04-10 23:01:12.265 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository(101): Delegation token receivers loaded successfully\n2024-04-10 23:01:12.266 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(189): Checking provider and receiver instances consistency\n2024-04-10 23:01:12.267 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(209): Provider and receiver instances are consistent\n2024-04-10 23:01:12.268 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(240): Obtaining delegation tokens\n2024-04-10 23:01:12.270 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(243): Delegation tokens obtained successfully\n2024-04-10 23:01:12.271 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(248): No tokens obtained so skipping notifications\n2024-04-10 23:01:12.272 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository(64): Loading delegation token receivers\n2024-04-10 23:01:12.275 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository(72): Delegation token receiver hadoopfs loaded and initialized\n2024-04-10 23:01:12.275 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository(72): Delegation token receiver hbase loaded and initialized\n2024-04-10 23:01:12.276 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository(101): Delegation token receivers loaded successfully\n2024-04-10 23:01:12.278 INFO  org.apache.flink.runtime.blob.BlobServer(164): Created BLOB server storage directory /var/folders/bh/zkcp61wj1kgd28r58g7bsmp00000gn/T/minicluster_8ae55a063802ad0482c68fdadc12494d/blobStorage\n2024-04-10 23:01:12.280 INFO  org.apache.flink.runtime.blob.BlobServer(238): Started BLOB server at 0.0.0.0:59361 - max concurrent requests: 50 - max backlog: 1000\n2024-04-10 23:01:20.263 INFO  org.apache.flink.runtime.blob.PermanentBlobCache(93): Created BLOB cache storage directory /var/folders/bh/zkcp61wj1kgd28r58g7bsmp00000gn/T/minicluster_8ae55a063802ad0482c68fdadc12494d/blobStorage\n2024-04-10 23:01:20.269 INFO  org.apache.flink.runtime.blob.TransientBlobCache(93): Created BLOB cache storage directory /var/folders/bh/zkcp61wj1kgd28r58g7bsmp00000gn/T/minicluster_8ae55a063802ad0482c68fdadc12494d/blobStorage\n2024-04-10 23:01:20.274 INFO  org.apache.flink.runtime.minicluster.MiniCluster(742): Starting 1 TaskManager(s)\n2024-04-10 23:01:20.278 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner(607): Starting TaskManager with ResourceID: 3a3dc4a2-1016-4458-8de1-c32de738132f\n2024-04-10 23:01:20.283 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices(499): Temporary file directory '/var/folders/bh/zkcp61wj1kgd28r58g7bsmp00000gn/T': total 465 GB, usable 4 GB (0.86% usable)\n2024-04-10 23:01:20.285 INFO  org.apache.flink.runtime.io.disk.iomanager.IOManager(60): Created a new FileChannelManager for spilling of task related data to disk (joins, sorting, ...). Used directories:\n\t/var/folders/bh/zkcp61wj1kgd28r58g7bsmp00000gn/T/flink-io-cd710b80-eb96-4ba7-990b-e307cd12cef5\n2024-04-10 23:01:20.291 INFO  org.apache.flink.runtime.io.network.NettyShuffleServiceFactory(166): Created a new FileChannelManager for storing result partitions of BLOCKING shuffles. Used directories:\n\t/var/folders/bh/zkcp61wj1kgd28r58g7bsmp00000gn/T/flink-netty-shuffle-a544169c-9fd2-44b7-a7e3-419dd99c5631\n2024-04-10 23:01:20.665 INFO  org.apache.flink.runtime.io.network.buffer.NetworkBufferPool(156): Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).\n2024-04-10 23:01:20.668 INFO  org.apache.flink.runtime.io.network.NettyShuffleEnvironment(353): Starting the network environment and its components.\n2024-04-10 23:01:20.672 INFO  org.apache.flink.runtime.taskexecutor.KvStateService(92): Starting the kvState service and its components.\n2024-04-10 23:01:20.675 INFO  org.apache.flink.configuration.Configuration(865): Config uses fallback configuration key 'pekko.ask.timeout' instead of key 'taskmanager.slot.timeout'\n2024-04-10 23:01:20.678 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService(271): Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at pekko://flink/user/rpc/taskmanager_8 .\n2024-04-10 23:01:20.685 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService(127): Start job leader service.\n2024-04-10 23:01:20.686 INFO  org.apache.flink.runtime.filecache.FileCache(116): User file cache uses directory /var/folders/bh/zkcp61wj1kgd28r58g7bsmp00000gn/T/flink-dist-cache-ca9246b7-92a3-4950-bee4-41d6de66110c\n2024-04-10 23:01:20.688 INFO  org.apache.flink.configuration.Configuration(865): Config uses fallback configuration key 'rest.port' instead of key 'rest.bind-port'\n2024-04-10 23:01:20.691 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint(180): Starting rest endpoint.\n2024-04-10 23:01:20.701 WARN  org.apache.flink.runtime.webmonitor.WebMonitorUtils(76): Log file environment variable 'log.file' is not set.\n2024-04-10 23:01:20.701 WARN  org.apache.flink.runtime.webmonitor.WebMonitorUtils(82): JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'web.log.path'.\n2024-04-10 23:01:20.715 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint(303): Rest endpoint listening at localhost:47193\n2024-04-10 23:01:20.716 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService(314): Proposing leadership to the contender that is registered under component ID 'rest_server'.\n2024-04-10 23:01:20.718 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint(1057): Web frontend listening at http://localhost:47193.\n2024-04-10 23:01:20.719 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint(1117): http://localhost:47193 was granted leadership with leaderSessionID=c388e03f-2fda-4209-894c-6e84be9065cc\n2024-04-10 23:01:20.720 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService(261): Received confirmation of leadership for leader http://localhost:47193 , session=c388e03f-2fda-4209-894c-6e84be9065cc\n2024-04-10 23:01:20.730 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService(314): Proposing leadership to the contender that is registered under component ID 'dispatcher'.\n2024-04-10 23:01:20.731 INFO  org.apache.flink.runtime.dispatcher.runner.DefaultDispatcherRunner(114): DefaultDispatcherRunner was granted leadership with leader id 483d8746-61fe-4fc2-9e4b-88f2d0f766ff. Creating new DispatcherLeaderProcess.\n2024-04-10 23:01:20.732 INFO  org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl(118): Starting resource manager service.\n2024-04-10 23:01:20.735 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService(314): Proposing leadership to the contender that is registered under component ID 'resource_manager'.\n2024-04-10 23:01:20.737 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess(99): Start SessionDispatcherLeaderProcess.\n2024-04-10 23:01:20.739 INFO  org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl(198): Resource manager service is granted leadership with session id b812043d-484d-46d5-918e-30f01c48acac.\n2024-04-10 23:01:20.741 INFO  org.apache.flink.runtime.minicluster.MiniCluster(508): Flink Mini Cluster started successfully\n2024-04-10 23:01:20.741 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess(144): Recover all persisted job graphs that are not finished, yet.\n2024-04-10 23:01:20.743 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess(158): Successfully recovered 0 persisted job graphs.\n2024-04-10 23:01:20.753 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService(271): Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at pekko://flink/user/rpc/resourcemanager_9 .\n2024-04-10 23:01:20.756 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService(271): Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at pekko://flink/user/rpc/dispatcher_10 .\n2024-04-10 23:01:20.776 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager(251): Starting the resource manager.\n2024-04-10 23:01:20.779 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager(212): Starting the slot manager.\n2024-04-10 23:01:20.779 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService(261): Received confirmation of leadership for leader pekko://flink/user/rpc/dispatcher_10 , session=483d8746-61fe-4fc2-9e4b-88f2d0f766ff\n2024-04-10 23:01:20.780 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(308): Starting tokens update task\n2024-04-10 23:01:20.780 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(320): No tokens obtained so skipping notifications\n2024-04-10 23:01:20.781 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(335): Tokens update task not started because either no tokens obtained or none of the tokens specified its renewal date\n2024-04-10 23:01:20.784 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService(261): Received confirmation of leadership for leader pekko://flink/user/rpc/resourcemanager_9 , session=b812043d-484d-46d5-918e-30f01c48acac\n2024-04-10 23:01:20.792 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor(1422): Connecting to ResourceManager pekko://flink/user/rpc/resourcemanager_9(918e30f01c48acacb812043d484d46d5).\n2024-04-10 23:01:20.891 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor(162): Resolved ResourceManager address, beginning registration\n2024-04-10 23:01:20.900 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager(1033): Registering TaskManager with ResourceID 3a3dc4a2-1016-4458-8de1-c32de738132f (pekko://flink/user/rpc/taskmanager_8) at ResourceManager\n2024-04-10 23:01:20.903 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor(99): Successful registration at resource manager pekko://flink/user/rpc/resourcemanager_9 under registration id b3d40d933196909fc6b32f85ed8ea198.\n2024-04-10 23:01:20.905 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager(344): Registering task executor 3a3dc4a2-1016-4458-8de1-c32de738132f under b3d40d933196909fc6b32f85ed8ea198 at the slot manager.\n2024-04-10 23:01:20.906 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher(515): Received JobGraph submission 'KafkaReader' (ff4837b6b74dc8f20c0a5bff35d3f0a5).\n2024-04-10 23:01:20.906 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher(602): Submitting job 'KafkaReader' (ff4837b6b74dc8f20c0a5bff35d3f0a5).\n2024-04-10 23:01:20.907 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService(314): Proposing leadership to the contender that is registered under component ID 'job-ff4837b6b74dc8f20c0a5bff35d3f0a5'.\n2024-04-10 23:01:20.908 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner(318): JobMasterServiceLeadershipRunner for job ff4837b6b74dc8f20c0a5bff35d3f0a5 was granted leadership with leader id 07f63542-0bf5-48b6-bc2f-deb69155d01f. Creating new JobMasterServiceProcess.\n2024-04-10 23:01:20.910 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService(271): Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_11 .\n2024-04-10 23:01:20.918 INFO  org.apache.flink.runtime.jobmaster.JobMaster(319): Initializing job 'KafkaReader' (ff4837b6b74dc8f20c0a5bff35d3f0a5).\n2024-04-10 23:01:20.922 INFO  org.apache.flink.runtime.jobmaster.JobMaster(106): Using restart back off time strategy NoRestartBackoffTimeStrategy for KafkaReader (ff4837b6b74dc8f20c0a5bff35d3f0a5).\n2024-04-10 23:01:20.926 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph(393): Created execution graph a1f9559f9c54f2cf756b118e6dd29e5c for job ff4837b6b74dc8f20c0a5bff35d3f0a5.\n2024-04-10 23:01:20.928 INFO  org.apache.flink.runtime.jobmaster.JobMaster(179): Running initialization on master for job KafkaReader (ff4837b6b74dc8f20c0a5bff35d3f0a5).\n2024-04-10 23:01:20.928 INFO  org.apache.flink.runtime.jobmaster.JobMaster(208): Successfully ran initialization on master in 0 ms.\n2024-04-10 23:01:20.949 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology(416): Built 1 new pipelined regions in 1 ms, total 1 pipelined regions currently.\n2024-04-10 23:01:20.950 INFO  org.apache.flink.runtime.jobmaster.JobMaster(263): No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@65635b87\n2024-04-10 23:01:20.951 INFO  org.apache.flink.runtime.state.StateBackendLoader(321): State backend loader loads the state backend as HashMapStateBackend\n2024-04-10 23:01:20.951 INFO  org.apache.flink.runtime.jobmaster.JobMaster(274): Checkpoint storage is set to 'jobmanager'\n2024-04-10 23:01:20.959 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator(1705): No checkpoint found during restore.\n2024-04-10 23:01:20.960 INFO  org.apache.flink.runtime.jobmaster.JobMaster(168): Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@1a57c5f for KafkaReader (ff4837b6b74dc8f20c0a5bff35d3f0a5).\n2024-04-10 23:01:20.963 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService(261): Received confirmation of leadership for leader pekko://flink/user/rpc/jobmanager_11 , session=07f63542-0bf5-48b6-bc2f-deb69155d01f\n2024-04-10 23:01:20.964 INFO  org.apache.flink.runtime.jobmaster.JobMaster(986): Starting execution of job 'KafkaReader' (ff4837b6b74dc8f20c0a5bff35d3f0a5) under job master id bc2fdeb69155d01f07f635420bf548b6.\n2024-04-10 23:01:20.969 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator(205): Starting split enumerator for source Source: test[7].\n2024-04-10 23:01:20.974 INFO  org.apache.flink.runtime.jobmaster.JobMaster(239): Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]\n2024-04-10 23:01:20.975 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph(1146): Job KafkaReader (ff4837b6b74dc8f20c0a5bff35d3f0a5) switched from state CREATED to RUNNING.\n2024-04-10 23:01:20.976 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph(1442): Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1) (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.\n2024-04-10 23:01:20.976 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig(376): AdminClientConfig values: \n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [127.0.0.1:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tclient.id = testGroup-enumerator-admin-client\n\tconnections.max.idle.ms = 300000\n\tdefault.api.timeout.ms = 60000\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.connect.timeout.ms = null\n\tsasl.login.read.timeout.ms = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.login.retry.backoff.max.ms = 10000\n\tsasl.login.retry.backoff.ms = 100\n\tsasl.mechanism = GSSAPI\n\tsasl.oauthbearer.clock.skew.seconds = 30\n\tsasl.oauthbearer.expected.audience = null\n\tsasl.oauthbearer.expected.issuer = null\n\tsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\n\tsasl.oauthbearer.jwks.endpoint.url = null\n\tsasl.oauthbearer.scope.claim.name = scope\n\tsasl.oauthbearer.sub.claim.name = sub\n\tsasl.oauthbearer.token.endpoint.url = null\n\tsecurity.protocol = PLAINTEXT\n\tsecurity.providers = null\n\tsend.buffer.bytes = 131072\n\tsocket.connection.setup.timeout.max.ms = 30000\n\tsocket.connection.setup.timeout.ms = 10000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.2\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\n2024-04-10 23:01:20.980 INFO  org.apache.flink.runtime.jobmaster.JobMaster(1181): Connecting to ResourceManager pekko://flink/user/rpc/resourcemanager_9(918e30f01c48acacb812043d484d46d5)\n2024-04-10 23:01:20.982 INFO  org.apache.flink.runtime.jobmaster.JobMaster(162): Resolved ResourceManager address, beginning registration\n2024-04-10 23:01:20.983 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager(388): Registering job manager bc2fdeb69155d01f07f635420bf548b6@pekko://flink/user/rpc/jobmanager_11 for job ff4837b6b74dc8f20c0a5bff35d3f0a5.\n2024-04-10 23:01:20.985 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig(385): These configurations '[key.deserializer, value.deserializer, enable.auto.commit, group.id, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.\n2024-04-10 23:01:20.986 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(119): Kafka version: 3.7.0\n2024-04-10 23:01:20.987 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(120): Kafka commitId: 2ae524ed625438c5\n2024-04-10 23:01:20.988 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(121): Kafka startTimeMs: 1712761280986\n2024-04-10 23:01:20.989 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator(166): Starting the KafkaSourceEnumerator for consumer group testGroup with partition discovery interval of 300000 ms.\n2024-04-10 23:01:20.992 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager(968): Registered job manager bc2fdeb69155d01f07f635420bf548b6@pekko://flink/user/rpc/jobmanager_11 for job ff4837b6b74dc8f20c0a5bff35d3f0a5.\n2024-04-10 23:01:21.000 INFO  org.apache.flink.runtime.jobmaster.JobMaster(1205): JobManager successfully registered at ResourceManager, leader id: 918e30f01c48acacb812043d484d46d5.\n2024-04-10 23:01:21.004 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager(324): Received resource requirements from job ff4837b6b74dc8f20c0a5bff35d3f0a5: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]\n2024-04-10 23:01:21.036 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator(424): Discovered new partitions: [test-0]\n2024-04-10 23:01:21.067 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager(709): Matching resource requirements against available resources.\nMissing resources:\n\t Job ff4837b6b74dc8f20c0a5bff35d3f0a5\n\t\tResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}\nCurrent resources:\n\tTaskManager 3a3dc4a2-1016-4458-8de1-c32de738132f\n\t\tAvailable: ResourceProfile{taskHeapMemory=1024.000gb (1099511627776 bytes), taskOffHeapMemory=1024.000gb (1099511627776 bytes), managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}\n\t\tTotal:     ResourceProfile{taskHeapMemory=1024.000gb (1099511627776 bytes), taskOffHeapMemory=1024.000gb (1099511627776 bytes), managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}\n2024-04-10 23:01:21.067 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer(112): Starting allocation of slot 4f8252b55f3c3f6c691783ee0c7ff5b4 from 3a3dc4a2-1016-4458-8de1-c32de738132f for job ff4837b6b74dc8f20c0a5bff35d3f0a5 with resource profile ResourceProfile{taskHeapMemory=1024.000gb (1099511627776 bytes), taskOffHeapMemory=1024.000gb (1099511627776 bytes), managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}.\n2024-04-10 23:01:21.069 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor(1121): Receive slot request 4f8252b55f3c3f6c691783ee0c7ff5b4 for job ff4837b6b74dc8f20c0a5bff35d3f0a5 from resource manager with leader id 918e30f01c48acacb812043d484d46d5.\n2024-04-10 23:01:21.070 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl(320): Allocated slot for 4f8252b55f3c3f6c691783ee0c7ff5b4 with resources ResourceProfile{taskHeapMemory=1024.000gb (1099511627776 bytes), taskOffHeapMemory=1024.000gb (1099511627776 bytes), managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}.\n2024-04-10 23:01:21.072 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService(192): Add job ff4837b6b74dc8f20c0a5bff35d3f0a5 for job leader monitoring.\n2024-04-10 23:01:21.072 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService(350): Try to register at job manager pekko://flink/user/rpc/jobmanager_11 with leader id 07f63542-0bf5-48b6-bc2f-deb69155d01f.\n2024-04-10 23:01:21.074 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService(162): Resolved JobManager address, beginning registration\n2024-04-10 23:01:21.077 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService(417): Successful registration at job manager pekko://flink/user/rpc/jobmanager_11 for job ff4837b6b74dc8f20c0a5bff35d3f0a5.\n2024-04-10 23:01:21.078 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor(1727): Establish JobManager connection for job ff4837b6b74dc8f20c0a5bff35d3f0a5.\n2024-04-10 23:01:21.079 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor(1577): Offer reserved slots to the leader of job ff4837b6b74dc8f20c0a5bff35d3f0a5.\n2024-04-10 23:01:21.081 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph(1442): Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1) (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.\n2024-04-10 23:01:21.082 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph(563): Deploying Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1) (attempt #0) with attempt id a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to 3a3dc4a2-1016-4458-8de1-c32de738132f @ localhost (dataPort=-1) with allocation id 4f8252b55f3c3f6c691783ee0c7ff5b4\n2024-04-10 23:01:21.085 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl(390): Activate slot 4f8252b55f3c3f6c691783ee0c7ff5b4.\n2024-04-10 23:01:21.086 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl(390): Activate slot 4f8252b55f3c3f6c691783ee0c7ff5b4.\n2024-04-10 23:01:21.092 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader(106): Creating a changelog storage with name 'memory'.\n2024-04-10 23:01:21.093 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager(70): Creating the channel state executor factory for job id ff4837b6b74dc8f20c0a5bff35d3f0a5\n2024-04-10 23:01:21.094 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor(797): Received task Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1)#0 (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id 4f8252b55f3c3f6c691783ee0c7ff5b4.\n2024-04-10 23:01:21.095 INFO  org.apache.flink.runtime.taskmanager.Task(1085): Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1)#0 (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.\n2024-04-10 23:01:21.095 INFO  org.apache.flink.runtime.taskmanager.Task(622): Loading JAR files for task Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1)#0 (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].\n2024-04-10 23:01:21.099 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask(263): No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@7c2af71f\n2024-04-10 23:01:21.099 INFO  org.apache.flink.runtime.state.StateBackendLoader(321): State backend loader loads the state backend as HashMapStateBackend\n2024-04-10 23:01:21.099 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask(274): Checkpoint storage is set to 'jobmanager'\n2024-04-10 23:01:21.100 INFO  org.apache.flink.runtime.taskmanager.Task(1085): Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1)#0 (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.\n2024-04-10 23:01:21.102 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph(1442): Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1) (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.\n2024-04-10 23:01:21.237 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.ProducerConfig(376): ProducerConfig values: \n\tacks = -1\n\tauto.include.jmx.reporter = true\n\tbatch.size = 16384\n\tbootstrap.servers = [127.0.0.1:9092]\n\tbuffer.memory = 33554432\n\tclient.dns.lookup = use_all_dns_ips\n\tclient.id = producer-2\n\tcompression.type = none\n\tconnections.max.idle.ms = 540000\n\tdelivery.timeout.ms = 120000\n\tenable.idempotence = true\n\tinterceptor.classes = []\n\tkey.serializer = class org.apache.flink.kafka.shaded.org.apache.kafka.common.serialization.ByteArraySerializer\n\tlinger.ms = 0\n\tmax.block.ms = 60000\n\tmax.in.flight.requests.per.connection = 5\n\tmax.request.size = 1048576\n\tmetadata.max.age.ms = 300000\n\tmetadata.max.idle.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartitioner.adaptive.partitioning.enable = true\n\tpartitioner.availability.timeout.ms = 0\n\tpartitioner.class = null\n\tpartitioner.ignore.keys = false\n\treceive.buffer.bytes = 32768\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.connect.timeout.ms = null\n\tsasl.login.read.timeout.ms = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.login.retry.backoff.max.ms = 10000\n\tsasl.login.retry.backoff.ms = 100\n\tsasl.mechanism = GSSAPI\n\tsasl.oauthbearer.clock.skew.seconds = 30\n\tsasl.oauthbearer.expected.audience = null\n\tsasl.oauthbearer.expected.issuer = null\n\tsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\n\tsasl.oauthbearer.jwks.endpoint.url = null\n\tsasl.oauthbearer.scope.claim.name = scope\n\tsasl.oauthbearer.sub.claim.name = sub\n\tsasl.oauthbearer.token.endpoint.url = null\n\tsecurity.protocol = PLAINTEXT\n\tsecurity.providers = null\n\tsend.buffer.bytes = 131072\n\tsocket.connection.setup.timeout.max.ms = 30000\n\tsocket.connection.setup.timeout.ms = 10000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.2\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttransaction.timeout.ms = 3600000\n\ttransactional.id = null\n\tvalue.serializer = class org.apache.flink.kafka.shaded.org.apache.kafka.common.serialization.ByteArraySerializer\n\n2024-04-10 23:01:21.254 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.KafkaProducer(596): [Producer clientId=producer-2] Instantiated an idempotent producer.\n2024-04-10 23:01:21.263 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.ProducerConfig(385): These configurations '[group.id]' were supplied but are not used yet.\n2024-04-10 23:01:21.265 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(119): Kafka version: 3.7.0\n2024-04-10 23:01:21.265 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(120): Kafka commitId: 2ae524ed625438c5\n2024-04-10 23:01:21.268 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(121): Kafka startTimeMs: 1712761281265\n2024-04-10 23:01:21.281 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator(598): Source Source: test[7] registering reader for parallel task 0 (#0) @ \n2024-04-10 23:01:21.282 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator(384): Assigning splits to readers {0=[[Partition: test-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}\n2024-04-10 23:01:21.281 INFO  org.apache.flink.runtime.taskmanager.Task(1085): Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1)#0 (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.\n2024-04-10 23:01:21.288 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph(1442): Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1) (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.\n2024-04-10 23:01:21.290 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase(265): Adding split(s) to reader: [[Partition: test-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]\n2024-04-10 23:01:21.294 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.ConsumerConfig(376): ConsumerConfig values: \n\tallow.auto.create.topics = true\n\tauto.commit.interval.ms = 5000\n\tauto.include.jmx.reporter = true\n\tauto.offset.reset = earliest\n\tbootstrap.servers = [127.0.0.1:9092]\n\tcheck.crcs = true\n\tclient.dns.lookup = use_all_dns_ips\n\tclient.id = testGroup-0\n\tclient.rack = \n\tconnections.max.idle.ms = 540000\n\tdefault.api.timeout.ms = 60000\n\tenable.auto.commit = false\n\texclude.internal.topics = true\n\tfetch.max.bytes = 52428800\n\tfetch.max.wait.ms = 500\n\tfetch.min.bytes = 1\n\tgroup.id = testGroup\n\tgroup.instance.id = null\n\theartbeat.interval.ms = 3000\n\tinterceptor.classes = []\n\tinternal.leave.group.on.close = true\n\tinternal.throw.on.fetch.stable.offset.unsupported = false\n\tisolation.level = read_uncommitted\n\tkey.deserializer = class org.apache.flink.kafka.shaded.org.apache.kafka.common.serialization.ByteArrayDeserializer\n\tmax.partition.fetch.bytes = 1048576\n\tmax.poll.interval.ms = 300000\n\tmax.poll.records = 500\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartition.assignment.strategy = [class org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.CooperativeStickyAssignor]\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.connect.timeout.ms = null\n\tsasl.login.read.timeout.ms = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.login.retry.backoff.max.ms = 10000\n\tsasl.login.retry.backoff.ms = 100\n\tsasl.mechanism = GSSAPI\n\tsasl.oauthbearer.clock.skew.seconds = 30\n\tsasl.oauthbearer.expected.audience = null\n\tsasl.oauthbearer.expected.issuer = null\n\tsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\n\tsasl.oauthbearer.jwks.endpoint.url = null\n\tsasl.oauthbearer.scope.claim.name = scope\n\tsasl.oauthbearer.sub.claim.name = sub\n\tsasl.oauthbearer.token.endpoint.url = null\n\tsecurity.protocol = PLAINTEXT\n\tsecurity.providers = null\n\tsend.buffer.bytes = 131072\n\tsession.timeout.ms = 45000\n\tsocket.connection.setup.timeout.max.ms = 30000\n\tsocket.connection.setup.timeout.ms = 10000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.2\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\tvalue.deserializer = class org.apache.flink.kafka.shaded.org.apache.kafka.common.serialization.ByteArrayDeserializer\n\n2024-04-10 23:01:21.299 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.Metadata(287): [Producer clientId=producer-2] Cluster ID: 4ITBRX7KQhiCewPd219uAw\n2024-04-10 23:01:21.311 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.ConsumerConfig(385): These configurations '[client.id.prefix, partition.discovery.interval.ms]' were supplied but are not used yet.\n2024-04-10 23:01:21.311 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(119): Kafka version: 3.7.0\n2024-04-10 23:01:21.311 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(120): Kafka commitId: 2ae524ed625438c5\n2024-04-10 23:01:21.312 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(121): Kafka startTimeMs: 1712761281311\n2024-04-10 23:01:21.312 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.internals.TransactionManager(440): [Producer clientId=producer-2] ProducerId set to 8 with epoch 0\n2024-04-10 23:01:21.315 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher(115): Starting split fetcher 0\n2024-04-10 23:01:21.317 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.KafkaConsumer(1124): [Consumer clientId=testGroup-0, groupId=testGroup] Assigned to partition(s): test-0\n2024-04-10 23:01:21.318 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.internals.SubscriptionState(647): [Consumer clientId=testGroup-0, groupId=testGroup] Seeking to earliest offset of partition test-0\n2024-04-10 23:01:21.342 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.Metadata(402): [Consumer clientId=testGroup-0, groupId=testGroup] Resetting the last seen epoch of partition test-0 to 0 since the associated topicId changed from null to u16Uv8NXRsO485KT_fMEyA\n2024-04-10 23:01:21.343 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.Metadata(287): [Consumer clientId=testGroup-0, groupId=testGroup] Cluster ID: 4ITBRX7KQhiCewPd219uAw\n2024-04-10 23:01:21.355 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.internals.SubscriptionState(399): [Consumer clientId=testGroup-0, groupId=testGroup] Resetting offset for partition test-0 to position FetchPosition{offset=299167022, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.0.30:9092 (id: 0 rack: null)], epoch=0}}.\n2024-04-10 23:01:21.549 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.ProducerConfig(376): ProducerConfig values: \n\tacks = -1\n\tauto.include.jmx.reporter = true\n\tbatch.size = 16384\n\tbootstrap.servers = [127.0.0.1:9092]\n\tbuffer.memory = 33554432\n\tclient.dns.lookup = use_all_dns_ips\n\tclient.id = producer-3\n\tcompression.type = none\n\tconnections.max.idle.ms = 540000\n\tdelivery.timeout.ms = 120000\n\tenable.idempotence = true\n\tinterceptor.classes = []\n\tkey.serializer = class org.apache.flink.kafka.shaded.org.apache.kafka.common.serialization.ByteArraySerializer\n\tlinger.ms = 0\n\tmax.block.ms = 60000\n\tmax.in.flight.requests.per.connection = 5\n\tmax.request.size = 1048576\n\tmetadata.max.age.ms = 300000\n\tmetadata.max.idle.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartitioner.adaptive.partitioning.enable = true\n\tpartitioner.availability.timeout.ms = 0\n\tpartitioner.class = null\n\tpartitioner.ignore.keys = false\n\treceive.buffer.bytes = 32768\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.connect.timeout.ms = null\n\tsasl.login.read.timeout.ms = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.login.retry.backoff.max.ms = 10000\n\tsasl.login.retry.backoff.ms = 100\n\tsasl.mechanism = GSSAPI\n\tsasl.oauthbearer.clock.skew.seconds = 30\n\tsasl.oauthbearer.expected.audience = null\n\tsasl.oauthbearer.expected.issuer = null\n\tsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\n\tsasl.oauthbearer.jwks.endpoint.url = null\n\tsasl.oauthbearer.scope.claim.name = scope\n\tsasl.oauthbearer.sub.claim.name = sub\n\tsasl.oauthbearer.token.endpoint.url = null\n\tsecurity.protocol = PLAINTEXT\n\tsecurity.providers = null\n\tsend.buffer.bytes = 131072\n\tsocket.connection.setup.timeout.max.ms = 30000\n\tsocket.connection.setup.timeout.ms = 10000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.2\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttransaction.timeout.ms = 3600000\n\ttransactional.id = null\n\tvalue.serializer = class org.apache.flink.kafka.shaded.org.apache.kafka.common.serialization.ByteArraySerializer\n\n2024-04-10 23:01:21.552 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.KafkaProducer(596): [Producer clientId=producer-3] Instantiated an idempotent producer.\n2024-04-10 23:01:21.629 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.ProducerConfig(385): These configurations '[group.id]' were supplied but are not used yet.\n2024-04-10 23:01:21.631 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(119): Kafka version: 3.7.0\n2024-04-10 23:01:21.632 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(120): Kafka commitId: 2ae524ed625438c5\n2024-04-10 23:01:21.632 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(121): Kafka startTimeMs: 1712761281630\n2024-04-10 23:01:21.671 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.Metadata(402): [Producer clientId=producer-3] Resetting the last seen epoch of partition test_kafka-0 to 0 since the associated topicId changed from null to SkIw21tiSSuP5LzQGe7TMA\n2024-04-10 23:01:21.672 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.Metadata(287): [Producer clientId=producer-3] Cluster ID: 4ITBRX7KQhiCewPd219uAw\n2024-04-10 23:01:21.673 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.internals.TransactionManager(440): [Producer clientId=producer-3] ProducerId set to 9 with epoch 0\n2024-04-10 23:01:21.679 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.KafkaProducer(1310): [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.\n2024-04-10 23:01:21.685 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics(693): Metrics scheduler closed\n2024-04-10 23:01:21.686 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics(697): Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter\n2024-04-10 23:01:21.687 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics(703): Metrics reporters closed\n2024-04-10 23:01:21.688 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(83): App info kafka.producer for producer-3 unregistered\n2024-04-10 23:01:21.699 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.Metadata(402): [Producer clientId=producer-2] Resetting the last seen epoch of partition test_kafka-0 to 0 since the associated topicId changed from null to SkIw21tiSSuP5LzQGe7TMA\n2024-04-10 23:01:26.090 INFO  org.dinky.service.impl.TaskServiceImpl(192): execute job finished,status is SUCCESS\nProcess Step SUBMIT_EXECUTE exit with status:FINISHED\n","startTime":"2024-04-10 23:00:49.701","status":"FINISHED","time":36393,"title":"执行作业","type":"SUBMIT_EXECUTE"}],"endTime":"2024-04-10 23:01:26.119","key":"ea6af0f0-3294-4efa-873a-a345376d8a44","lastUpdateStep":{"children":[{"children":[],"endTime":"2024-04-10 23:00:49.754","key":"b61cde53-efd1-478a-a882-6ad6fb5d1334","log":"Start Process Step:SUBMIT_BUILD_CONFIG\n2024-04-10 23:00:49.710 INFO  org.dinky.service.impl.TaskServiceImpl(286): Start initialize FlinkSQLEnv:\n2024-04-10 23:00:49.712 INFO  org.dinky.service.impl.TaskServiceImpl(306): Initializing data permissions...\n2024-04-10 23:00:49.730 INFO  org.dinky.service.impl.TaskServiceImpl(308): Finish initialize FlinkSQLEnv.\n2024-04-10 23:00:49.752 INFO  org.dinky.service.impl.TaskServiceImpl(236): Init remote cluster\nProcess Step SUBMIT_BUILD_CONFIG exit with status:FINISHED\n","startTime":"2024-04-10 23:00:49.709","status":"FINISHED","time":45,"title":"构建配置信息","type":"SUBMIT_BUILD_CONFIG"}],"endTime":"2024-04-10 23:01:26.094","key":"5fe00de0-2ecd-4c0d-be76-7357b68ee226","log":"Start Process Step:SUBMIT_EXECUTE\n2024-04-10 23:00:49.887 INFO  org.dinky.service.task.FlinkSqlTask(67): Initializing Flink job config...\n2024-04-10 23:00:49.917 INFO  org.dinky.job.builder.JobUDFBuilder(115): A total of 0 UDF have been Init.\n2024-04-10 23:00:49.919 INFO  org.dinky.job.builder.JobUDFBuilder(116): Initializing Flink UDF...Finish\n2024-04-10 23:00:49.921 INFO  org.dinky.utils.KerberosUtil(58): Simple authentication mode\n2024-04-10 23:00:49.930 INFO  org.dinky.utils.KerberosUtil(58): Simple authentication mode\n2024-04-10 23:00:50.130 INFO  org.apache.flink.configuration.Configuration(865): Config uses fallback configuration key 'rest.port' instead of key 'rest.bind-port'\n2024-04-10 23:00:50.132 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils(281): The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.\n2024-04-10 23:00:50.133 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils(281): The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.\n2024-04-10 23:00:50.134 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils(281): The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.\n2024-04-10 23:00:50.134 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils(281): The configuration option taskmanager.memory.network.min required for local execution is not set, setting it to its default value 64 mb.\n2024-04-10 23:00:50.136 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils(281): The configuration option taskmanager.memory.network.max required for local execution is not set, setting it to its default value 64 mb.\n2024-04-10 23:00:50.138 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils(281): The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.\n2024-04-10 23:00:50.140 INFO  org.apache.flink.runtime.minicluster.MiniCluster(322): Starting Flink Mini Cluster\n2024-04-10 23:00:50.662 INFO  org.apache.flink.runtime.minicluster.MiniCluster(341): Starting Metrics Registry\n2024-04-10 23:01:10.398 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl(142): No metrics reporter configured, no metrics will be exposed/reported.\n2024-04-10 23:01:10.399 INFO  org.apache.flink.runtime.minicluster.MiniCluster(348): Starting RPC Service(s)\n2024-04-10 23:01:10.429 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils(225): Trying to start local actor system\n2024-04-10 23:01:11.676 INFO  org.apache.pekko.event.slf4j.Slf4jLogger(117): Slf4jLogger started\n2024-04-10 23:01:12.055 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils(255): Actor system started at pekko://flink\n2024-04-10 23:01:12.081 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils(225): Trying to start local actor system\n2024-04-10 23:01:12.112 INFO  org.apache.pekko.event.slf4j.Slf4jLogger(117): Slf4jLogger started\n2024-04-10 23:01:12.136 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils(255): Actor system started at pekko://flink-metrics\n2024-04-10 23:01:12.225 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService(271): Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at pekko://flink-metrics/user/rpc/MetricQueryService .\n2024-04-10 23:01:12.249 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(127): Loading delegation token providers\n2024-04-10 23:01:12.254 WARN  org.apache.flink.runtime.util.HadoopUtils(139): Could not find Hadoop configuration via any of the supported methods (Flink configuration, environment variables).\n2024-04-10 23:01:12.256 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(135): Delegation token provider hadoopfs loaded and initialized\n2024-04-10 23:01:12.258 WARN  org.apache.flink.runtime.util.HadoopUtils(139): Could not find Hadoop configuration via any of the supported methods (Flink configuration, environment variables).\n2024-04-10 23:01:12.259 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(135): Delegation token provider hbase loaded and initialized\n2024-04-10 23:01:12.260 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(165): Delegation token providers loaded successfully\n2024-04-10 23:01:12.261 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository(64): Loading delegation token receivers\n2024-04-10 23:01:12.263 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository(72): Delegation token receiver hadoopfs loaded and initialized\n2024-04-10 23:01:12.264 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository(72): Delegation token receiver hbase loaded and initialized\n2024-04-10 23:01:12.265 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository(101): Delegation token receivers loaded successfully\n2024-04-10 23:01:12.266 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(189): Checking provider and receiver instances consistency\n2024-04-10 23:01:12.267 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(209): Provider and receiver instances are consistent\n2024-04-10 23:01:12.268 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(240): Obtaining delegation tokens\n2024-04-10 23:01:12.270 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(243): Delegation tokens obtained successfully\n2024-04-10 23:01:12.271 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(248): No tokens obtained so skipping notifications\n2024-04-10 23:01:12.272 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository(64): Loading delegation token receivers\n2024-04-10 23:01:12.275 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository(72): Delegation token receiver hadoopfs loaded and initialized\n2024-04-10 23:01:12.275 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository(72): Delegation token receiver hbase loaded and initialized\n2024-04-10 23:01:12.276 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository(101): Delegation token receivers loaded successfully\n2024-04-10 23:01:12.278 INFO  org.apache.flink.runtime.blob.BlobServer(164): Created BLOB server storage directory /var/folders/bh/zkcp61wj1kgd28r58g7bsmp00000gn/T/minicluster_8ae55a063802ad0482c68fdadc12494d/blobStorage\n2024-04-10 23:01:12.280 INFO  org.apache.flink.runtime.blob.BlobServer(238): Started BLOB server at 0.0.0.0:59361 - max concurrent requests: 50 - max backlog: 1000\n2024-04-10 23:01:20.263 INFO  org.apache.flink.runtime.blob.PermanentBlobCache(93): Created BLOB cache storage directory /var/folders/bh/zkcp61wj1kgd28r58g7bsmp00000gn/T/minicluster_8ae55a063802ad0482c68fdadc12494d/blobStorage\n2024-04-10 23:01:20.269 INFO  org.apache.flink.runtime.blob.TransientBlobCache(93): Created BLOB cache storage directory /var/folders/bh/zkcp61wj1kgd28r58g7bsmp00000gn/T/minicluster_8ae55a063802ad0482c68fdadc12494d/blobStorage\n2024-04-10 23:01:20.274 INFO  org.apache.flink.runtime.minicluster.MiniCluster(742): Starting 1 TaskManager(s)\n2024-04-10 23:01:20.278 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner(607): Starting TaskManager with ResourceID: 3a3dc4a2-1016-4458-8de1-c32de738132f\n2024-04-10 23:01:20.283 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices(499): Temporary file directory '/var/folders/bh/zkcp61wj1kgd28r58g7bsmp00000gn/T': total 465 GB, usable 4 GB (0.86% usable)\n2024-04-10 23:01:20.285 INFO  org.apache.flink.runtime.io.disk.iomanager.IOManager(60): Created a new FileChannelManager for spilling of task related data to disk (joins, sorting, ...). Used directories:\n\t/var/folders/bh/zkcp61wj1kgd28r58g7bsmp00000gn/T/flink-io-cd710b80-eb96-4ba7-990b-e307cd12cef5\n2024-04-10 23:01:20.291 INFO  org.apache.flink.runtime.io.network.NettyShuffleServiceFactory(166): Created a new FileChannelManager for storing result partitions of BLOCKING shuffles. Used directories:\n\t/var/folders/bh/zkcp61wj1kgd28r58g7bsmp00000gn/T/flink-netty-shuffle-a544169c-9fd2-44b7-a7e3-419dd99c5631\n2024-04-10 23:01:20.665 INFO  org.apache.flink.runtime.io.network.buffer.NetworkBufferPool(156): Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).\n2024-04-10 23:01:20.668 INFO  org.apache.flink.runtime.io.network.NettyShuffleEnvironment(353): Starting the network environment and its components.\n2024-04-10 23:01:20.672 INFO  org.apache.flink.runtime.taskexecutor.KvStateService(92): Starting the kvState service and its components.\n2024-04-10 23:01:20.675 INFO  org.apache.flink.configuration.Configuration(865): Config uses fallback configuration key 'pekko.ask.timeout' instead of key 'taskmanager.slot.timeout'\n2024-04-10 23:01:20.678 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService(271): Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at pekko://flink/user/rpc/taskmanager_8 .\n2024-04-10 23:01:20.685 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService(127): Start job leader service.\n2024-04-10 23:01:20.686 INFO  org.apache.flink.runtime.filecache.FileCache(116): User file cache uses directory /var/folders/bh/zkcp61wj1kgd28r58g7bsmp00000gn/T/flink-dist-cache-ca9246b7-92a3-4950-bee4-41d6de66110c\n2024-04-10 23:01:20.688 INFO  org.apache.flink.configuration.Configuration(865): Config uses fallback configuration key 'rest.port' instead of key 'rest.bind-port'\n2024-04-10 23:01:20.691 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint(180): Starting rest endpoint.\n2024-04-10 23:01:20.701 WARN  org.apache.flink.runtime.webmonitor.WebMonitorUtils(76): Log file environment variable 'log.file' is not set.\n2024-04-10 23:01:20.701 WARN  org.apache.flink.runtime.webmonitor.WebMonitorUtils(82): JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'web.log.path'.\n2024-04-10 23:01:20.715 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint(303): Rest endpoint listening at localhost:47193\n2024-04-10 23:01:20.716 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService(314): Proposing leadership to the contender that is registered under component ID 'rest_server'.\n2024-04-10 23:01:20.718 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint(1057): Web frontend listening at http://localhost:47193.\n2024-04-10 23:01:20.719 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint(1117): http://localhost:47193 was granted leadership with leaderSessionID=c388e03f-2fda-4209-894c-6e84be9065cc\n2024-04-10 23:01:20.720 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService(261): Received confirmation of leadership for leader http://localhost:47193 , session=c388e03f-2fda-4209-894c-6e84be9065cc\n2024-04-10 23:01:20.730 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService(314): Proposing leadership to the contender that is registered under component ID 'dispatcher'.\n2024-04-10 23:01:20.731 INFO  org.apache.flink.runtime.dispatcher.runner.DefaultDispatcherRunner(114): DefaultDispatcherRunner was granted leadership with leader id 483d8746-61fe-4fc2-9e4b-88f2d0f766ff. Creating new DispatcherLeaderProcess.\n2024-04-10 23:01:20.732 INFO  org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl(118): Starting resource manager service.\n2024-04-10 23:01:20.735 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService(314): Proposing leadership to the contender that is registered under component ID 'resource_manager'.\n2024-04-10 23:01:20.737 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess(99): Start SessionDispatcherLeaderProcess.\n2024-04-10 23:01:20.739 INFO  org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl(198): Resource manager service is granted leadership with session id b812043d-484d-46d5-918e-30f01c48acac.\n2024-04-10 23:01:20.741 INFO  org.apache.flink.runtime.minicluster.MiniCluster(508): Flink Mini Cluster started successfully\n2024-04-10 23:01:20.741 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess(144): Recover all persisted job graphs that are not finished, yet.\n2024-04-10 23:01:20.743 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess(158): Successfully recovered 0 persisted job graphs.\n2024-04-10 23:01:20.753 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService(271): Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at pekko://flink/user/rpc/resourcemanager_9 .\n2024-04-10 23:01:20.756 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService(271): Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at pekko://flink/user/rpc/dispatcher_10 .\n2024-04-10 23:01:20.776 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager(251): Starting the resource manager.\n2024-04-10 23:01:20.779 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager(212): Starting the slot manager.\n2024-04-10 23:01:20.779 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService(261): Received confirmation of leadership for leader pekko://flink/user/rpc/dispatcher_10 , session=483d8746-61fe-4fc2-9e4b-88f2d0f766ff\n2024-04-10 23:01:20.780 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(308): Starting tokens update task\n2024-04-10 23:01:20.780 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(320): No tokens obtained so skipping notifications\n2024-04-10 23:01:20.781 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(335): Tokens update task not started because either no tokens obtained or none of the tokens specified its renewal date\n2024-04-10 23:01:20.784 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService(261): Received confirmation of leadership for leader pekko://flink/user/rpc/resourcemanager_9 , session=b812043d-484d-46d5-918e-30f01c48acac\n2024-04-10 23:01:20.792 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor(1422): Connecting to ResourceManager pekko://flink/user/rpc/resourcemanager_9(918e30f01c48acacb812043d484d46d5).\n2024-04-10 23:01:20.891 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor(162): Resolved ResourceManager address, beginning registration\n2024-04-10 23:01:20.900 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager(1033): Registering TaskManager with ResourceID 3a3dc4a2-1016-4458-8de1-c32de738132f (pekko://flink/user/rpc/taskmanager_8) at ResourceManager\n2024-04-10 23:01:20.903 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor(99): Successful registration at resource manager pekko://flink/user/rpc/resourcemanager_9 under registration id b3d40d933196909fc6b32f85ed8ea198.\n2024-04-10 23:01:20.905 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager(344): Registering task executor 3a3dc4a2-1016-4458-8de1-c32de738132f under b3d40d933196909fc6b32f85ed8ea198 at the slot manager.\n2024-04-10 23:01:20.906 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher(515): Received JobGraph submission 'KafkaReader' (ff4837b6b74dc8f20c0a5bff35d3f0a5).\n2024-04-10 23:01:20.906 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher(602): Submitting job 'KafkaReader' (ff4837b6b74dc8f20c0a5bff35d3f0a5).\n2024-04-10 23:01:20.907 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService(314): Proposing leadership to the contender that is registered under component ID 'job-ff4837b6b74dc8f20c0a5bff35d3f0a5'.\n2024-04-10 23:01:20.908 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner(318): JobMasterServiceLeadershipRunner for job ff4837b6b74dc8f20c0a5bff35d3f0a5 was granted leadership with leader id 07f63542-0bf5-48b6-bc2f-deb69155d01f. Creating new JobMasterServiceProcess.\n2024-04-10 23:01:20.910 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService(271): Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_11 .\n2024-04-10 23:01:20.918 INFO  org.apache.flink.runtime.jobmaster.JobMaster(319): Initializing job 'KafkaReader' (ff4837b6b74dc8f20c0a5bff35d3f0a5).\n2024-04-10 23:01:20.922 INFO  org.apache.flink.runtime.jobmaster.JobMaster(106): Using restart back off time strategy NoRestartBackoffTimeStrategy for KafkaReader (ff4837b6b74dc8f20c0a5bff35d3f0a5).\n2024-04-10 23:01:20.926 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph(393): Created execution graph a1f9559f9c54f2cf756b118e6dd29e5c for job ff4837b6b74dc8f20c0a5bff35d3f0a5.\n2024-04-10 23:01:20.928 INFO  org.apache.flink.runtime.jobmaster.JobMaster(179): Running initialization on master for job KafkaReader (ff4837b6b74dc8f20c0a5bff35d3f0a5).\n2024-04-10 23:01:20.928 INFO  org.apache.flink.runtime.jobmaster.JobMaster(208): Successfully ran initialization on master in 0 ms.\n2024-04-10 23:01:20.949 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology(416): Built 1 new pipelined regions in 1 ms, total 1 pipelined regions currently.\n2024-04-10 23:01:20.950 INFO  org.apache.flink.runtime.jobmaster.JobMaster(263): No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@65635b87\n2024-04-10 23:01:20.951 INFO  org.apache.flink.runtime.state.StateBackendLoader(321): State backend loader loads the state backend as HashMapStateBackend\n2024-04-10 23:01:20.951 INFO  org.apache.flink.runtime.jobmaster.JobMaster(274): Checkpoint storage is set to 'jobmanager'\n2024-04-10 23:01:20.959 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator(1705): No checkpoint found during restore.\n2024-04-10 23:01:20.960 INFO  org.apache.flink.runtime.jobmaster.JobMaster(168): Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@1a57c5f for KafkaReader (ff4837b6b74dc8f20c0a5bff35d3f0a5).\n2024-04-10 23:01:20.963 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService(261): Received confirmation of leadership for leader pekko://flink/user/rpc/jobmanager_11 , session=07f63542-0bf5-48b6-bc2f-deb69155d01f\n2024-04-10 23:01:20.964 INFO  org.apache.flink.runtime.jobmaster.JobMaster(986): Starting execution of job 'KafkaReader' (ff4837b6b74dc8f20c0a5bff35d3f0a5) under job master id bc2fdeb69155d01f07f635420bf548b6.\n2024-04-10 23:01:20.969 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator(205): Starting split enumerator for source Source: test[7].\n2024-04-10 23:01:20.974 INFO  org.apache.flink.runtime.jobmaster.JobMaster(239): Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]\n2024-04-10 23:01:20.975 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph(1146): Job KafkaReader (ff4837b6b74dc8f20c0a5bff35d3f0a5) switched from state CREATED to RUNNING.\n2024-04-10 23:01:20.976 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph(1442): Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1) (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.\n2024-04-10 23:01:20.976 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig(376): AdminClientConfig values: \n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [127.0.0.1:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tclient.id = testGroup-enumerator-admin-client\n\tconnections.max.idle.ms = 300000\n\tdefault.api.timeout.ms = 60000\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.connect.timeout.ms = null\n\tsasl.login.read.timeout.ms = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.login.retry.backoff.max.ms = 10000\n\tsasl.login.retry.backoff.ms = 100\n\tsasl.mechanism = GSSAPI\n\tsasl.oauthbearer.clock.skew.seconds = 30\n\tsasl.oauthbearer.expected.audience = null\n\tsasl.oauthbearer.expected.issuer = null\n\tsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\n\tsasl.oauthbearer.jwks.endpoint.url = null\n\tsasl.oauthbearer.scope.claim.name = scope\n\tsasl.oauthbearer.sub.claim.name = sub\n\tsasl.oauthbearer.token.endpoint.url = null\n\tsecurity.protocol = PLAINTEXT\n\tsecurity.providers = null\n\tsend.buffer.bytes = 131072\n\tsocket.connection.setup.timeout.max.ms = 30000\n\tsocket.connection.setup.timeout.ms = 10000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.2\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\n2024-04-10 23:01:20.980 INFO  org.apache.flink.runtime.jobmaster.JobMaster(1181): Connecting to ResourceManager pekko://flink/user/rpc/resourcemanager_9(918e30f01c48acacb812043d484d46d5)\n2024-04-10 23:01:20.982 INFO  org.apache.flink.runtime.jobmaster.JobMaster(162): Resolved ResourceManager address, beginning registration\n2024-04-10 23:01:20.983 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager(388): Registering job manager bc2fdeb69155d01f07f635420bf548b6@pekko://flink/user/rpc/jobmanager_11 for job ff4837b6b74dc8f20c0a5bff35d3f0a5.\n2024-04-10 23:01:20.985 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig(385): These configurations '[key.deserializer, value.deserializer, enable.auto.commit, group.id, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.\n2024-04-10 23:01:20.986 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(119): Kafka version: 3.7.0\n2024-04-10 23:01:20.987 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(120): Kafka commitId: 2ae524ed625438c5\n2024-04-10 23:01:20.988 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(121): Kafka startTimeMs: 1712761280986\n2024-04-10 23:01:20.989 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator(166): Starting the KafkaSourceEnumerator for consumer group testGroup with partition discovery interval of 300000 ms.\n2024-04-10 23:01:20.992 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager(968): Registered job manager bc2fdeb69155d01f07f635420bf548b6@pekko://flink/user/rpc/jobmanager_11 for job ff4837b6b74dc8f20c0a5bff35d3f0a5.\n2024-04-10 23:01:21.000 INFO  org.apache.flink.runtime.jobmaster.JobMaster(1205): JobManager successfully registered at ResourceManager, leader id: 918e30f01c48acacb812043d484d46d5.\n2024-04-10 23:01:21.004 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager(324): Received resource requirements from job ff4837b6b74dc8f20c0a5bff35d3f0a5: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]\n2024-04-10 23:01:21.036 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator(424): Discovered new partitions: [test-0]\n2024-04-10 23:01:21.067 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager(709): Matching resource requirements against available resources.\nMissing resources:\n\t Job ff4837b6b74dc8f20c0a5bff35d3f0a5\n\t\tResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}\nCurrent resources:\n\tTaskManager 3a3dc4a2-1016-4458-8de1-c32de738132f\n\t\tAvailable: ResourceProfile{taskHeapMemory=1024.000gb (1099511627776 bytes), taskOffHeapMemory=1024.000gb (1099511627776 bytes), managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}\n\t\tTotal:     ResourceProfile{taskHeapMemory=1024.000gb (1099511627776 bytes), taskOffHeapMemory=1024.000gb (1099511627776 bytes), managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}\n2024-04-10 23:01:21.067 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer(112): Starting allocation of slot 4f8252b55f3c3f6c691783ee0c7ff5b4 from 3a3dc4a2-1016-4458-8de1-c32de738132f for job ff4837b6b74dc8f20c0a5bff35d3f0a5 with resource profile ResourceProfile{taskHeapMemory=1024.000gb (1099511627776 bytes), taskOffHeapMemory=1024.000gb (1099511627776 bytes), managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}.\n2024-04-10 23:01:21.069 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor(1121): Receive slot request 4f8252b55f3c3f6c691783ee0c7ff5b4 for job ff4837b6b74dc8f20c0a5bff35d3f0a5 from resource manager with leader id 918e30f01c48acacb812043d484d46d5.\n2024-04-10 23:01:21.070 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl(320): Allocated slot for 4f8252b55f3c3f6c691783ee0c7ff5b4 with resources ResourceProfile{taskHeapMemory=1024.000gb (1099511627776 bytes), taskOffHeapMemory=1024.000gb (1099511627776 bytes), managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}.\n2024-04-10 23:01:21.072 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService(192): Add job ff4837b6b74dc8f20c0a5bff35d3f0a5 for job leader monitoring.\n2024-04-10 23:01:21.072 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService(350): Try to register at job manager pekko://flink/user/rpc/jobmanager_11 with leader id 07f63542-0bf5-48b6-bc2f-deb69155d01f.\n2024-04-10 23:01:21.074 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService(162): Resolved JobManager address, beginning registration\n2024-04-10 23:01:21.077 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService(417): Successful registration at job manager pekko://flink/user/rpc/jobmanager_11 for job ff4837b6b74dc8f20c0a5bff35d3f0a5.\n2024-04-10 23:01:21.078 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor(1727): Establish JobManager connection for job ff4837b6b74dc8f20c0a5bff35d3f0a5.\n2024-04-10 23:01:21.079 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor(1577): Offer reserved slots to the leader of job ff4837b6b74dc8f20c0a5bff35d3f0a5.\n2024-04-10 23:01:21.081 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph(1442): Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1) (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.\n2024-04-10 23:01:21.082 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph(563): Deploying Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1) (attempt #0) with attempt id a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to 3a3dc4a2-1016-4458-8de1-c32de738132f @ localhost (dataPort=-1) with allocation id 4f8252b55f3c3f6c691783ee0c7ff5b4\n2024-04-10 23:01:21.085 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl(390): Activate slot 4f8252b55f3c3f6c691783ee0c7ff5b4.\n2024-04-10 23:01:21.086 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl(390): Activate slot 4f8252b55f3c3f6c691783ee0c7ff5b4.\n2024-04-10 23:01:21.092 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader(106): Creating a changelog storage with name 'memory'.\n2024-04-10 23:01:21.093 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager(70): Creating the channel state executor factory for job id ff4837b6b74dc8f20c0a5bff35d3f0a5\n2024-04-10 23:01:21.094 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor(797): Received task Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1)#0 (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id 4f8252b55f3c3f6c691783ee0c7ff5b4.\n2024-04-10 23:01:21.095 INFO  org.apache.flink.runtime.taskmanager.Task(1085): Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1)#0 (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.\n2024-04-10 23:01:21.095 INFO  org.apache.flink.runtime.taskmanager.Task(622): Loading JAR files for task Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1)#0 (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].\n2024-04-10 23:01:21.099 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask(263): No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@7c2af71f\n2024-04-10 23:01:21.099 INFO  org.apache.flink.runtime.state.StateBackendLoader(321): State backend loader loads the state backend as HashMapStateBackend\n2024-04-10 23:01:21.099 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask(274): Checkpoint storage is set to 'jobmanager'\n2024-04-10 23:01:21.100 INFO  org.apache.flink.runtime.taskmanager.Task(1085): Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1)#0 (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.\n2024-04-10 23:01:21.102 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph(1442): Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1) (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.\n2024-04-10 23:01:21.237 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.ProducerConfig(376): ProducerConfig values: \n\tacks = -1\n\tauto.include.jmx.reporter = true\n\tbatch.size = 16384\n\tbootstrap.servers = [127.0.0.1:9092]\n\tbuffer.memory = 33554432\n\tclient.dns.lookup = use_all_dns_ips\n\tclient.id = producer-2\n\tcompression.type = none\n\tconnections.max.idle.ms = 540000\n\tdelivery.timeout.ms = 120000\n\tenable.idempotence = true\n\tinterceptor.classes = []\n\tkey.serializer = class org.apache.flink.kafka.shaded.org.apache.kafka.common.serialization.ByteArraySerializer\n\tlinger.ms = 0\n\tmax.block.ms = 60000\n\tmax.in.flight.requests.per.connection = 5\n\tmax.request.size = 1048576\n\tmetadata.max.age.ms = 300000\n\tmetadata.max.idle.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartitioner.adaptive.partitioning.enable = true\n\tpartitioner.availability.timeout.ms = 0\n\tpartitioner.class = null\n\tpartitioner.ignore.keys = false\n\treceive.buffer.bytes = 32768\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.connect.timeout.ms = null\n\tsasl.login.read.timeout.ms = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.login.retry.backoff.max.ms = 10000\n\tsasl.login.retry.backoff.ms = 100\n\tsasl.mechanism = GSSAPI\n\tsasl.oauthbearer.clock.skew.seconds = 30\n\tsasl.oauthbearer.expected.audience = null\n\tsasl.oauthbearer.expected.issuer = null\n\tsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\n\tsasl.oauthbearer.jwks.endpoint.url = null\n\tsasl.oauthbearer.scope.claim.name = scope\n\tsasl.oauthbearer.sub.claim.name = sub\n\tsasl.oauthbearer.token.endpoint.url = null\n\tsecurity.protocol = PLAINTEXT\n\tsecurity.providers = null\n\tsend.buffer.bytes = 131072\n\tsocket.connection.setup.timeout.max.ms = 30000\n\tsocket.connection.setup.timeout.ms = 10000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.2\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttransaction.timeout.ms = 3600000\n\ttransactional.id = null\n\tvalue.serializer = class org.apache.flink.kafka.shaded.org.apache.kafka.common.serialization.ByteArraySerializer\n\n2024-04-10 23:01:21.254 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.KafkaProducer(596): [Producer clientId=producer-2] Instantiated an idempotent producer.\n2024-04-10 23:01:21.263 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.ProducerConfig(385): These configurations '[group.id]' were supplied but are not used yet.\n2024-04-10 23:01:21.265 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(119): Kafka version: 3.7.0\n2024-04-10 23:01:21.265 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(120): Kafka commitId: 2ae524ed625438c5\n2024-04-10 23:01:21.268 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(121): Kafka startTimeMs: 1712761281265\n2024-04-10 23:01:21.281 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator(598): Source Source: test[7] registering reader for parallel task 0 (#0) @ \n2024-04-10 23:01:21.282 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator(384): Assigning splits to readers {0=[[Partition: test-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}\n2024-04-10 23:01:21.281 INFO  org.apache.flink.runtime.taskmanager.Task(1085): Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1)#0 (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.\n2024-04-10 23:01:21.288 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph(1442): Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1) (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.\n2024-04-10 23:01:21.290 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase(265): Adding split(s) to reader: [[Partition: test-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]\n2024-04-10 23:01:21.294 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.ConsumerConfig(376): ConsumerConfig values: \n\tallow.auto.create.topics = true\n\tauto.commit.interval.ms = 5000\n\tauto.include.jmx.reporter = true\n\tauto.offset.reset = earliest\n\tbootstrap.servers = [127.0.0.1:9092]\n\tcheck.crcs = true\n\tclient.dns.lookup = use_all_dns_ips\n\tclient.id = testGroup-0\n\tclient.rack = \n\tconnections.max.idle.ms = 540000\n\tdefault.api.timeout.ms = 60000\n\tenable.auto.commit = false\n\texclude.internal.topics = true\n\tfetch.max.bytes = 52428800\n\tfetch.max.wait.ms = 500\n\tfetch.min.bytes = 1\n\tgroup.id = testGroup\n\tgroup.instance.id = null\n\theartbeat.interval.ms = 3000\n\tinterceptor.classes = []\n\tinternal.leave.group.on.close = true\n\tinternal.throw.on.fetch.stable.offset.unsupported = false\n\tisolation.level = read_uncommitted\n\tkey.deserializer = class org.apache.flink.kafka.shaded.org.apache.kafka.common.serialization.ByteArrayDeserializer\n\tmax.partition.fetch.bytes = 1048576\n\tmax.poll.interval.ms = 300000\n\tmax.poll.records = 500\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartition.assignment.strategy = [class org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.CooperativeStickyAssignor]\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.connect.timeout.ms = null\n\tsasl.login.read.timeout.ms = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.login.retry.backoff.max.ms = 10000\n\tsasl.login.retry.backoff.ms = 100\n\tsasl.mechanism = GSSAPI\n\tsasl.oauthbearer.clock.skew.seconds = 30\n\tsasl.oauthbearer.expected.audience = null\n\tsasl.oauthbearer.expected.issuer = null\n\tsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\n\tsasl.oauthbearer.jwks.endpoint.url = null\n\tsasl.oauthbearer.scope.claim.name = scope\n\tsasl.oauthbearer.sub.claim.name = sub\n\tsasl.oauthbearer.token.endpoint.url = null\n\tsecurity.protocol = PLAINTEXT\n\tsecurity.providers = null\n\tsend.buffer.bytes = 131072\n\tsession.timeout.ms = 45000\n\tsocket.connection.setup.timeout.max.ms = 30000\n\tsocket.connection.setup.timeout.ms = 10000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.2\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\tvalue.deserializer = class org.apache.flink.kafka.shaded.org.apache.kafka.common.serialization.ByteArrayDeserializer\n\n2024-04-10 23:01:21.299 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.Metadata(287): [Producer clientId=producer-2] Cluster ID: 4ITBRX7KQhiCewPd219uAw\n2024-04-10 23:01:21.311 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.ConsumerConfig(385): These configurations '[client.id.prefix, partition.discovery.interval.ms]' were supplied but are not used yet.\n2024-04-10 23:01:21.311 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(119): Kafka version: 3.7.0\n2024-04-10 23:01:21.311 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(120): Kafka commitId: 2ae524ed625438c5\n2024-04-10 23:01:21.312 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(121): Kafka startTimeMs: 1712761281311\n2024-04-10 23:01:21.312 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.internals.TransactionManager(440): [Producer clientId=producer-2] ProducerId set to 8 with epoch 0\n2024-04-10 23:01:21.315 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher(115): Starting split fetcher 0\n2024-04-10 23:01:21.317 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.KafkaConsumer(1124): [Consumer clientId=testGroup-0, groupId=testGroup] Assigned to partition(s): test-0\n2024-04-10 23:01:21.318 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.internals.SubscriptionState(647): [Consumer clientId=testGroup-0, groupId=testGroup] Seeking to earliest offset of partition test-0\n2024-04-10 23:01:21.342 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.Metadata(402): [Consumer clientId=testGroup-0, groupId=testGroup] Resetting the last seen epoch of partition test-0 to 0 since the associated topicId changed from null to u16Uv8NXRsO485KT_fMEyA\n2024-04-10 23:01:21.343 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.Metadata(287): [Consumer clientId=testGroup-0, groupId=testGroup] Cluster ID: 4ITBRX7KQhiCewPd219uAw\n2024-04-10 23:01:21.355 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.internals.SubscriptionState(399): [Consumer clientId=testGroup-0, groupId=testGroup] Resetting offset for partition test-0 to position FetchPosition{offset=299167022, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.0.30:9092 (id: 0 rack: null)], epoch=0}}.\n2024-04-10 23:01:21.549 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.ProducerConfig(376): ProducerConfig values: \n\tacks = -1\n\tauto.include.jmx.reporter = true\n\tbatch.size = 16384\n\tbootstrap.servers = [127.0.0.1:9092]\n\tbuffer.memory = 33554432\n\tclient.dns.lookup = use_all_dns_ips\n\tclient.id = producer-3\n\tcompression.type = none\n\tconnections.max.idle.ms = 540000\n\tdelivery.timeout.ms = 120000\n\tenable.idempotence = true\n\tinterceptor.classes = []\n\tkey.serializer = class org.apache.flink.kafka.shaded.org.apache.kafka.common.serialization.ByteArraySerializer\n\tlinger.ms = 0\n\tmax.block.ms = 60000\n\tmax.in.flight.requests.per.connection = 5\n\tmax.request.size = 1048576\n\tmetadata.max.age.ms = 300000\n\tmetadata.max.idle.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartitioner.adaptive.partitioning.enable = true\n\tpartitioner.availability.timeout.ms = 0\n\tpartitioner.class = null\n\tpartitioner.ignore.keys = false\n\treceive.buffer.bytes = 32768\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.connect.timeout.ms = null\n\tsasl.login.read.timeout.ms = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.login.retry.backoff.max.ms = 10000\n\tsasl.login.retry.backoff.ms = 100\n\tsasl.mechanism = GSSAPI\n\tsasl.oauthbearer.clock.skew.seconds = 30\n\tsasl.oauthbearer.expected.audience = null\n\tsasl.oauthbearer.expected.issuer = null\n\tsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\n\tsasl.oauthbearer.jwks.endpoint.url = null\n\tsasl.oauthbearer.scope.claim.name = scope\n\tsasl.oauthbearer.sub.claim.name = sub\n\tsasl.oauthbearer.token.endpoint.url = null\n\tsecurity.protocol = PLAINTEXT\n\tsecurity.providers = null\n\tsend.buffer.bytes = 131072\n\tsocket.connection.setup.timeout.max.ms = 30000\n\tsocket.connection.setup.timeout.ms = 10000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.2\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttransaction.timeout.ms = 3600000\n\ttransactional.id = null\n\tvalue.serializer = class org.apache.flink.kafka.shaded.org.apache.kafka.common.serialization.ByteArraySerializer\n\n2024-04-10 23:01:21.552 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.KafkaProducer(596): [Producer clientId=producer-3] Instantiated an idempotent producer.\n2024-04-10 23:01:21.629 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.ProducerConfig(385): These configurations '[group.id]' were supplied but are not used yet.\n2024-04-10 23:01:21.631 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(119): Kafka version: 3.7.0\n2024-04-10 23:01:21.632 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(120): Kafka commitId: 2ae524ed625438c5\n2024-04-10 23:01:21.632 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(121): Kafka startTimeMs: 1712761281630\n2024-04-10 23:01:21.671 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.Metadata(402): [Producer clientId=producer-3] Resetting the last seen epoch of partition test_kafka-0 to 0 since the associated topicId changed from null to SkIw21tiSSuP5LzQGe7TMA\n2024-04-10 23:01:21.672 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.Metadata(287): [Producer clientId=producer-3] Cluster ID: 4ITBRX7KQhiCewPd219uAw\n2024-04-10 23:01:21.673 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.internals.TransactionManager(440): [Producer clientId=producer-3] ProducerId set to 9 with epoch 0\n2024-04-10 23:01:21.679 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.KafkaProducer(1310): [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.\n2024-04-10 23:01:21.685 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics(693): Metrics scheduler closed\n2024-04-10 23:01:21.686 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics(697): Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter\n2024-04-10 23:01:21.687 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics(703): Metrics reporters closed\n2024-04-10 23:01:21.688 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(83): App info kafka.producer for producer-3 unregistered\n2024-04-10 23:01:21.699 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.Metadata(402): [Producer clientId=producer-2] Resetting the last seen epoch of partition test_kafka-0 to 0 since the associated topicId changed from null to SkIw21tiSSuP5LzQGe7TMA\n2024-04-10 23:01:26.090 INFO  org.dinky.service.impl.TaskServiceImpl(192): execute job finished,status is SUCCESS\nProcess Step SUBMIT_EXECUTE exit with status:FINISHED\n","startTime":"2024-04-10 23:00:49.701","status":"FINISHED","time":36393,"title":"执行作业","type":"SUBMIT_EXECUTE"},"log":"Start Process:FlinkSubmit/4\nStart Process Step:SUBMIT_PRECHECK\n2024-04-10 23:00:49.700 INFO  org.dinky.service.impl.TaskServiceImpl(177): Start check and config task, task:KafkaReader\nProcess Step SUBMIT_PRECHECK exit with status:FINISHED\nStart Process Step:SUBMIT_EXECUTE\nStart Process Step:SUBMIT_BUILD_CONFIG\n2024-04-10 23:00:49.710 INFO  org.dinky.service.impl.TaskServiceImpl(286): Start initialize FlinkSQLEnv:\n2024-04-10 23:00:49.712 INFO  org.dinky.service.impl.TaskServiceImpl(306): Initializing data permissions...\n2024-04-10 23:00:49.730 INFO  org.dinky.service.impl.TaskServiceImpl(308): Finish initialize FlinkSQLEnv.\n2024-04-10 23:00:49.752 INFO  org.dinky.service.impl.TaskServiceImpl(236): Init remote cluster\nProcess Step SUBMIT_BUILD_CONFIG exit with status:FINISHED\n2024-04-10 23:00:49.887 INFO  org.dinky.service.task.FlinkSqlTask(67): Initializing Flink job config...\n2024-04-10 23:00:49.917 INFO  org.dinky.job.builder.JobUDFBuilder(115): A total of 0 UDF have been Init.\n2024-04-10 23:00:49.919 INFO  org.dinky.job.builder.JobUDFBuilder(116): Initializing Flink UDF...Finish\n2024-04-10 23:00:49.921 INFO  org.dinky.utils.KerberosUtil(58): Simple authentication mode\n2024-04-10 23:00:49.930 INFO  org.dinky.utils.KerberosUtil(58): Simple authentication mode\n2024-04-10 23:00:50.130 INFO  org.apache.flink.configuration.Configuration(865): Config uses fallback configuration key 'rest.port' instead of key 'rest.bind-port'\n2024-04-10 23:00:50.132 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils(281): The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.\n2024-04-10 23:00:50.133 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils(281): The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.\n2024-04-10 23:00:50.134 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils(281): The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.\n2024-04-10 23:00:50.134 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils(281): The configuration option taskmanager.memory.network.min required for local execution is not set, setting it to its default value 64 mb.\n2024-04-10 23:00:50.136 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils(281): The configuration option taskmanager.memory.network.max required for local execution is not set, setting it to its default value 64 mb.\n2024-04-10 23:00:50.138 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils(281): The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.\n2024-04-10 23:00:50.140 INFO  org.apache.flink.runtime.minicluster.MiniCluster(322): Starting Flink Mini Cluster\n2024-04-10 23:00:50.662 INFO  org.apache.flink.runtime.minicluster.MiniCluster(341): Starting Metrics Registry\n2024-04-10 23:01:10.398 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl(142): No metrics reporter configured, no metrics will be exposed/reported.\n2024-04-10 23:01:10.399 INFO  org.apache.flink.runtime.minicluster.MiniCluster(348): Starting RPC Service(s)\n2024-04-10 23:01:10.429 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils(225): Trying to start local actor system\n2024-04-10 23:01:11.676 INFO  org.apache.pekko.event.slf4j.Slf4jLogger(117): Slf4jLogger started\n2024-04-10 23:01:12.055 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils(255): Actor system started at pekko://flink\n2024-04-10 23:01:12.081 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils(225): Trying to start local actor system\n2024-04-10 23:01:12.112 INFO  org.apache.pekko.event.slf4j.Slf4jLogger(117): Slf4jLogger started\n2024-04-10 23:01:12.136 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcServiceUtils(255): Actor system started at pekko://flink-metrics\n2024-04-10 23:01:12.225 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService(271): Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at pekko://flink-metrics/user/rpc/MetricQueryService .\n2024-04-10 23:01:12.249 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(127): Loading delegation token providers\n2024-04-10 23:01:12.254 WARN  org.apache.flink.runtime.util.HadoopUtils(139): Could not find Hadoop configuration via any of the supported methods (Flink configuration, environment variables).\n2024-04-10 23:01:12.256 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(135): Delegation token provider hadoopfs loaded and initialized\n2024-04-10 23:01:12.258 WARN  org.apache.flink.runtime.util.HadoopUtils(139): Could not find Hadoop configuration via any of the supported methods (Flink configuration, environment variables).\n2024-04-10 23:01:12.259 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(135): Delegation token provider hbase loaded and initialized\n2024-04-10 23:01:12.260 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(165): Delegation token providers loaded successfully\n2024-04-10 23:01:12.261 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository(64): Loading delegation token receivers\n2024-04-10 23:01:12.263 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository(72): Delegation token receiver hadoopfs loaded and initialized\n2024-04-10 23:01:12.264 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository(72): Delegation token receiver hbase loaded and initialized\n2024-04-10 23:01:12.265 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository(101): Delegation token receivers loaded successfully\n2024-04-10 23:01:12.266 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(189): Checking provider and receiver instances consistency\n2024-04-10 23:01:12.267 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(209): Provider and receiver instances are consistent\n2024-04-10 23:01:12.268 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(240): Obtaining delegation tokens\n2024-04-10 23:01:12.270 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(243): Delegation tokens obtained successfully\n2024-04-10 23:01:12.271 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(248): No tokens obtained so skipping notifications\n2024-04-10 23:01:12.272 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository(64): Loading delegation token receivers\n2024-04-10 23:01:12.275 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository(72): Delegation token receiver hadoopfs loaded and initialized\n2024-04-10 23:01:12.275 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository(72): Delegation token receiver hbase loaded and initialized\n2024-04-10 23:01:12.276 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository(101): Delegation token receivers loaded successfully\n2024-04-10 23:01:12.278 INFO  org.apache.flink.runtime.blob.BlobServer(164): Created BLOB server storage directory /var/folders/bh/zkcp61wj1kgd28r58g7bsmp00000gn/T/minicluster_8ae55a063802ad0482c68fdadc12494d/blobStorage\n2024-04-10 23:01:12.280 INFO  org.apache.flink.runtime.blob.BlobServer(238): Started BLOB server at 0.0.0.0:59361 - max concurrent requests: 50 - max backlog: 1000\n2024-04-10 23:01:20.263 INFO  org.apache.flink.runtime.blob.PermanentBlobCache(93): Created BLOB cache storage directory /var/folders/bh/zkcp61wj1kgd28r58g7bsmp00000gn/T/minicluster_8ae55a063802ad0482c68fdadc12494d/blobStorage\n2024-04-10 23:01:20.269 INFO  org.apache.flink.runtime.blob.TransientBlobCache(93): Created BLOB cache storage directory /var/folders/bh/zkcp61wj1kgd28r58g7bsmp00000gn/T/minicluster_8ae55a063802ad0482c68fdadc12494d/blobStorage\n2024-04-10 23:01:20.274 INFO  org.apache.flink.runtime.minicluster.MiniCluster(742): Starting 1 TaskManager(s)\n2024-04-10 23:01:20.278 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner(607): Starting TaskManager with ResourceID: 3a3dc4a2-1016-4458-8de1-c32de738132f\n2024-04-10 23:01:20.283 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices(499): Temporary file directory '/var/folders/bh/zkcp61wj1kgd28r58g7bsmp00000gn/T': total 465 GB, usable 4 GB (0.86% usable)\n2024-04-10 23:01:20.285 INFO  org.apache.flink.runtime.io.disk.iomanager.IOManager(60): Created a new FileChannelManager for spilling of task related data to disk (joins, sorting, ...). Used directories:\n\t/var/folders/bh/zkcp61wj1kgd28r58g7bsmp00000gn/T/flink-io-cd710b80-eb96-4ba7-990b-e307cd12cef5\n2024-04-10 23:01:20.291 INFO  org.apache.flink.runtime.io.network.NettyShuffleServiceFactory(166): Created a new FileChannelManager for storing result partitions of BLOCKING shuffles. Used directories:\n\t/var/folders/bh/zkcp61wj1kgd28r58g7bsmp00000gn/T/flink-netty-shuffle-a544169c-9fd2-44b7-a7e3-419dd99c5631\n2024-04-10 23:01:20.665 INFO  org.apache.flink.runtime.io.network.buffer.NetworkBufferPool(156): Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).\n2024-04-10 23:01:20.668 INFO  org.apache.flink.runtime.io.network.NettyShuffleEnvironment(353): Starting the network environment and its components.\n2024-04-10 23:01:20.672 INFO  org.apache.flink.runtime.taskexecutor.KvStateService(92): Starting the kvState service and its components.\n2024-04-10 23:01:20.675 INFO  org.apache.flink.configuration.Configuration(865): Config uses fallback configuration key 'pekko.ask.timeout' instead of key 'taskmanager.slot.timeout'\n2024-04-10 23:01:20.678 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService(271): Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at pekko://flink/user/rpc/taskmanager_8 .\n2024-04-10 23:01:20.685 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService(127): Start job leader service.\n2024-04-10 23:01:20.686 INFO  org.apache.flink.runtime.filecache.FileCache(116): User file cache uses directory /var/folders/bh/zkcp61wj1kgd28r58g7bsmp00000gn/T/flink-dist-cache-ca9246b7-92a3-4950-bee4-41d6de66110c\n2024-04-10 23:01:20.688 INFO  org.apache.flink.configuration.Configuration(865): Config uses fallback configuration key 'rest.port' instead of key 'rest.bind-port'\n2024-04-10 23:01:20.691 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint(180): Starting rest endpoint.\n2024-04-10 23:01:20.701 WARN  org.apache.flink.runtime.webmonitor.WebMonitorUtils(76): Log file environment variable 'log.file' is not set.\n2024-04-10 23:01:20.701 WARN  org.apache.flink.runtime.webmonitor.WebMonitorUtils(82): JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'web.log.path'.\n2024-04-10 23:01:20.715 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint(303): Rest endpoint listening at localhost:47193\n2024-04-10 23:01:20.716 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService(314): Proposing leadership to the contender that is registered under component ID 'rest_server'.\n2024-04-10 23:01:20.718 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint(1057): Web frontend listening at http://localhost:47193.\n2024-04-10 23:01:20.719 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint(1117): http://localhost:47193 was granted leadership with leaderSessionID=c388e03f-2fda-4209-894c-6e84be9065cc\n2024-04-10 23:01:20.720 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService(261): Received confirmation of leadership for leader http://localhost:47193 , session=c388e03f-2fda-4209-894c-6e84be9065cc\n2024-04-10 23:01:20.730 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService(314): Proposing leadership to the contender that is registered under component ID 'dispatcher'.\n2024-04-10 23:01:20.731 INFO  org.apache.flink.runtime.dispatcher.runner.DefaultDispatcherRunner(114): DefaultDispatcherRunner was granted leadership with leader id 483d8746-61fe-4fc2-9e4b-88f2d0f766ff. Creating new DispatcherLeaderProcess.\n2024-04-10 23:01:20.732 INFO  org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl(118): Starting resource manager service.\n2024-04-10 23:01:20.735 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService(314): Proposing leadership to the contender that is registered under component ID 'resource_manager'.\n2024-04-10 23:01:20.737 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess(99): Start SessionDispatcherLeaderProcess.\n2024-04-10 23:01:20.739 INFO  org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl(198): Resource manager service is granted leadership with session id b812043d-484d-46d5-918e-30f01c48acac.\n2024-04-10 23:01:20.741 INFO  org.apache.flink.runtime.minicluster.MiniCluster(508): Flink Mini Cluster started successfully\n2024-04-10 23:01:20.741 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess(144): Recover all persisted job graphs that are not finished, yet.\n2024-04-10 23:01:20.743 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess(158): Successfully recovered 0 persisted job graphs.\n2024-04-10 23:01:20.753 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService(271): Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at pekko://flink/user/rpc/resourcemanager_9 .\n2024-04-10 23:01:20.756 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService(271): Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at pekko://flink/user/rpc/dispatcher_10 .\n2024-04-10 23:01:20.776 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager(251): Starting the resource manager.\n2024-04-10 23:01:20.779 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager(212): Starting the slot manager.\n2024-04-10 23:01:20.779 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService(261): Received confirmation of leadership for leader pekko://flink/user/rpc/dispatcher_10 , session=483d8746-61fe-4fc2-9e4b-88f2d0f766ff\n2024-04-10 23:01:20.780 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(308): Starting tokens update task\n2024-04-10 23:01:20.780 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(320): No tokens obtained so skipping notifications\n2024-04-10 23:01:20.781 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager(335): Tokens update task not started because either no tokens obtained or none of the tokens specified its renewal date\n2024-04-10 23:01:20.784 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService(261): Received confirmation of leadership for leader pekko://flink/user/rpc/resourcemanager_9 , session=b812043d-484d-46d5-918e-30f01c48acac\n2024-04-10 23:01:20.792 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor(1422): Connecting to ResourceManager pekko://flink/user/rpc/resourcemanager_9(918e30f01c48acacb812043d484d46d5).\n2024-04-10 23:01:20.891 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor(162): Resolved ResourceManager address, beginning registration\n2024-04-10 23:01:20.900 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager(1033): Registering TaskManager with ResourceID 3a3dc4a2-1016-4458-8de1-c32de738132f (pekko://flink/user/rpc/taskmanager_8) at ResourceManager\n2024-04-10 23:01:20.903 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor(99): Successful registration at resource manager pekko://flink/user/rpc/resourcemanager_9 under registration id b3d40d933196909fc6b32f85ed8ea198.\n2024-04-10 23:01:20.905 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager(344): Registering task executor 3a3dc4a2-1016-4458-8de1-c32de738132f under b3d40d933196909fc6b32f85ed8ea198 at the slot manager.\n2024-04-10 23:01:20.906 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher(515): Received JobGraph submission 'KafkaReader' (ff4837b6b74dc8f20c0a5bff35d3f0a5).\n2024-04-10 23:01:20.906 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher(602): Submitting job 'KafkaReader' (ff4837b6b74dc8f20c0a5bff35d3f0a5).\n2024-04-10 23:01:20.907 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService(314): Proposing leadership to the contender that is registered under component ID 'job-ff4837b6b74dc8f20c0a5bff35d3f0a5'.\n2024-04-10 23:01:20.908 INFO  org.apache.flink.runtime.jobmaster.JobMasterServiceLeadershipRunner(318): JobMasterServiceLeadershipRunner for job ff4837b6b74dc8f20c0a5bff35d3f0a5 was granted leadership with leader id 07f63542-0bf5-48b6-bc2f-deb69155d01f. Creating new JobMasterServiceProcess.\n2024-04-10 23:01:20.910 INFO  org.apache.flink.runtime.rpc.pekko.PekkoRpcService(271): Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at pekko://flink/user/rpc/jobmanager_11 .\n2024-04-10 23:01:20.918 INFO  org.apache.flink.runtime.jobmaster.JobMaster(319): Initializing job 'KafkaReader' (ff4837b6b74dc8f20c0a5bff35d3f0a5).\n2024-04-10 23:01:20.922 INFO  org.apache.flink.runtime.jobmaster.JobMaster(106): Using restart back off time strategy NoRestartBackoffTimeStrategy for KafkaReader (ff4837b6b74dc8f20c0a5bff35d3f0a5).\n2024-04-10 23:01:20.926 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph(393): Created execution graph a1f9559f9c54f2cf756b118e6dd29e5c for job ff4837b6b74dc8f20c0a5bff35d3f0a5.\n2024-04-10 23:01:20.928 INFO  org.apache.flink.runtime.jobmaster.JobMaster(179): Running initialization on master for job KafkaReader (ff4837b6b74dc8f20c0a5bff35d3f0a5).\n2024-04-10 23:01:20.928 INFO  org.apache.flink.runtime.jobmaster.JobMaster(208): Successfully ran initialization on master in 0 ms.\n2024-04-10 23:01:20.949 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology(416): Built 1 new pipelined regions in 1 ms, total 1 pipelined regions currently.\n2024-04-10 23:01:20.950 INFO  org.apache.flink.runtime.jobmaster.JobMaster(263): No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@65635b87\n2024-04-10 23:01:20.951 INFO  org.apache.flink.runtime.state.StateBackendLoader(321): State backend loader loads the state backend as HashMapStateBackend\n2024-04-10 23:01:20.951 INFO  org.apache.flink.runtime.jobmaster.JobMaster(274): Checkpoint storage is set to 'jobmanager'\n2024-04-10 23:01:20.959 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator(1705): No checkpoint found during restore.\n2024-04-10 23:01:20.960 INFO  org.apache.flink.runtime.jobmaster.JobMaster(168): Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@1a57c5f for KafkaReader (ff4837b6b74dc8f20c0a5bff35d3f0a5).\n2024-04-10 23:01:20.963 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService(261): Received confirmation of leadership for leader pekko://flink/user/rpc/jobmanager_11 , session=07f63542-0bf5-48b6-bc2f-deb69155d01f\n2024-04-10 23:01:20.964 INFO  org.apache.flink.runtime.jobmaster.JobMaster(986): Starting execution of job 'KafkaReader' (ff4837b6b74dc8f20c0a5bff35d3f0a5) under job master id bc2fdeb69155d01f07f635420bf548b6.\n2024-04-10 23:01:20.969 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator(205): Starting split enumerator for source Source: test[7].\n2024-04-10 23:01:20.974 INFO  org.apache.flink.runtime.jobmaster.JobMaster(239): Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]\n2024-04-10 23:01:20.975 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph(1146): Job KafkaReader (ff4837b6b74dc8f20c0a5bff35d3f0a5) switched from state CREATED to RUNNING.\n2024-04-10 23:01:20.976 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph(1442): Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1) (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.\n2024-04-10 23:01:20.976 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig(376): AdminClientConfig values: \n\tauto.include.jmx.reporter = true\n\tbootstrap.servers = [127.0.0.1:9092]\n\tclient.dns.lookup = use_all_dns_ips\n\tclient.id = testGroup-enumerator-admin-client\n\tconnections.max.idle.ms = 300000\n\tdefault.api.timeout.ms = 60000\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.connect.timeout.ms = null\n\tsasl.login.read.timeout.ms = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.login.retry.backoff.max.ms = 10000\n\tsasl.login.retry.backoff.ms = 100\n\tsasl.mechanism = GSSAPI\n\tsasl.oauthbearer.clock.skew.seconds = 30\n\tsasl.oauthbearer.expected.audience = null\n\tsasl.oauthbearer.expected.issuer = null\n\tsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\n\tsasl.oauthbearer.jwks.endpoint.url = null\n\tsasl.oauthbearer.scope.claim.name = scope\n\tsasl.oauthbearer.sub.claim.name = sub\n\tsasl.oauthbearer.token.endpoint.url = null\n\tsecurity.protocol = PLAINTEXT\n\tsecurity.providers = null\n\tsend.buffer.bytes = 131072\n\tsocket.connection.setup.timeout.max.ms = 30000\n\tsocket.connection.setup.timeout.ms = 10000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.2\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\n2024-04-10 23:01:20.980 INFO  org.apache.flink.runtime.jobmaster.JobMaster(1181): Connecting to ResourceManager pekko://flink/user/rpc/resourcemanager_9(918e30f01c48acacb812043d484d46d5)\n2024-04-10 23:01:20.982 INFO  org.apache.flink.runtime.jobmaster.JobMaster(162): Resolved ResourceManager address, beginning registration\n2024-04-10 23:01:20.983 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager(388): Registering job manager bc2fdeb69155d01f07f635420bf548b6@pekko://flink/user/rpc/jobmanager_11 for job ff4837b6b74dc8f20c0a5bff35d3f0a5.\n2024-04-10 23:01:20.985 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.admin.AdminClientConfig(385): These configurations '[key.deserializer, value.deserializer, enable.auto.commit, group.id, client.id.prefix, partition.discovery.interval.ms, auto.offset.reset]' were supplied but are not used yet.\n2024-04-10 23:01:20.986 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(119): Kafka version: 3.7.0\n2024-04-10 23:01:20.987 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(120): Kafka commitId: 2ae524ed625438c5\n2024-04-10 23:01:20.988 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(121): Kafka startTimeMs: 1712761280986\n2024-04-10 23:01:20.989 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator(166): Starting the KafkaSourceEnumerator for consumer group testGroup with partition discovery interval of 300000 ms.\n2024-04-10 23:01:20.992 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager(968): Registered job manager bc2fdeb69155d01f07f635420bf548b6@pekko://flink/user/rpc/jobmanager_11 for job ff4837b6b74dc8f20c0a5bff35d3f0a5.\n2024-04-10 23:01:21.000 INFO  org.apache.flink.runtime.jobmaster.JobMaster(1205): JobManager successfully registered at ResourceManager, leader id: 918e30f01c48acacb812043d484d46d5.\n2024-04-10 23:01:21.004 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager(324): Received resource requirements from job ff4837b6b74dc8f20c0a5bff35d3f0a5: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]\n2024-04-10 23:01:21.036 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator(424): Discovered new partitions: [test-0]\n2024-04-10 23:01:21.067 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.FineGrainedSlotManager(709): Matching resource requirements against available resources.\nMissing resources:\n\t Job ff4837b6b74dc8f20c0a5bff35d3f0a5\n\t\tResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}\nCurrent resources:\n\tTaskManager 3a3dc4a2-1016-4458-8de1-c32de738132f\n\t\tAvailable: ResourceProfile{taskHeapMemory=1024.000gb (1099511627776 bytes), taskOffHeapMemory=1024.000gb (1099511627776 bytes), managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}\n\t\tTotal:     ResourceProfile{taskHeapMemory=1024.000gb (1099511627776 bytes), taskOffHeapMemory=1024.000gb (1099511627776 bytes), managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}\n2024-04-10 23:01:21.067 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DefaultSlotStatusSyncer(112): Starting allocation of slot 4f8252b55f3c3f6c691783ee0c7ff5b4 from 3a3dc4a2-1016-4458-8de1-c32de738132f for job ff4837b6b74dc8f20c0a5bff35d3f0a5 with resource profile ResourceProfile{taskHeapMemory=1024.000gb (1099511627776 bytes), taskOffHeapMemory=1024.000gb (1099511627776 bytes), managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}.\n2024-04-10 23:01:21.069 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor(1121): Receive slot request 4f8252b55f3c3f6c691783ee0c7ff5b4 for job ff4837b6b74dc8f20c0a5bff35d3f0a5 from resource manager with leader id 918e30f01c48acacb812043d484d46d5.\n2024-04-10 23:01:21.070 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl(320): Allocated slot for 4f8252b55f3c3f6c691783ee0c7ff5b4 with resources ResourceProfile{taskHeapMemory=1024.000gb (1099511627776 bytes), taskOffHeapMemory=1024.000gb (1099511627776 bytes), managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}.\n2024-04-10 23:01:21.072 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService(192): Add job ff4837b6b74dc8f20c0a5bff35d3f0a5 for job leader monitoring.\n2024-04-10 23:01:21.072 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService(350): Try to register at job manager pekko://flink/user/rpc/jobmanager_11 with leader id 07f63542-0bf5-48b6-bc2f-deb69155d01f.\n2024-04-10 23:01:21.074 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService(162): Resolved JobManager address, beginning registration\n2024-04-10 23:01:21.077 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService(417): Successful registration at job manager pekko://flink/user/rpc/jobmanager_11 for job ff4837b6b74dc8f20c0a5bff35d3f0a5.\n2024-04-10 23:01:21.078 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor(1727): Establish JobManager connection for job ff4837b6b74dc8f20c0a5bff35d3f0a5.\n2024-04-10 23:01:21.079 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor(1577): Offer reserved slots to the leader of job ff4837b6b74dc8f20c0a5bff35d3f0a5.\n2024-04-10 23:01:21.081 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph(1442): Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1) (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.\n2024-04-10 23:01:21.082 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph(563): Deploying Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1) (attempt #0) with attempt id a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to 3a3dc4a2-1016-4458-8de1-c32de738132f @ localhost (dataPort=-1) with allocation id 4f8252b55f3c3f6c691783ee0c7ff5b4\n2024-04-10 23:01:21.085 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl(390): Activate slot 4f8252b55f3c3f6c691783ee0c7ff5b4.\n2024-04-10 23:01:21.086 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl(390): Activate slot 4f8252b55f3c3f6c691783ee0c7ff5b4.\n2024-04-10 23:01:21.092 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader(106): Creating a changelog storage with name 'memory'.\n2024-04-10 23:01:21.093 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager(70): Creating the channel state executor factory for job id ff4837b6b74dc8f20c0a5bff35d3f0a5\n2024-04-10 23:01:21.094 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor(797): Received task Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1)#0 (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id 4f8252b55f3c3f6c691783ee0c7ff5b4.\n2024-04-10 23:01:21.095 INFO  org.apache.flink.runtime.taskmanager.Task(1085): Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1)#0 (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.\n2024-04-10 23:01:21.095 INFO  org.apache.flink.runtime.taskmanager.Task(622): Loading JAR files for task Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1)#0 (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].\n2024-04-10 23:01:21.099 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask(263): No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@7c2af71f\n2024-04-10 23:01:21.099 INFO  org.apache.flink.runtime.state.StateBackendLoader(321): State backend loader loads the state backend as HashMapStateBackend\n2024-04-10 23:01:21.099 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask(274): Checkpoint storage is set to 'jobmanager'\n2024-04-10 23:01:21.100 INFO  org.apache.flink.runtime.taskmanager.Task(1085): Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1)#0 (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.\n2024-04-10 23:01:21.102 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph(1442): Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1) (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.\n2024-04-10 23:01:21.237 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.ProducerConfig(376): ProducerConfig values: \n\tacks = -1\n\tauto.include.jmx.reporter = true\n\tbatch.size = 16384\n\tbootstrap.servers = [127.0.0.1:9092]\n\tbuffer.memory = 33554432\n\tclient.dns.lookup = use_all_dns_ips\n\tclient.id = producer-2\n\tcompression.type = none\n\tconnections.max.idle.ms = 540000\n\tdelivery.timeout.ms = 120000\n\tenable.idempotence = true\n\tinterceptor.classes = []\n\tkey.serializer = class org.apache.flink.kafka.shaded.org.apache.kafka.common.serialization.ByteArraySerializer\n\tlinger.ms = 0\n\tmax.block.ms = 60000\n\tmax.in.flight.requests.per.connection = 5\n\tmax.request.size = 1048576\n\tmetadata.max.age.ms = 300000\n\tmetadata.max.idle.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartitioner.adaptive.partitioning.enable = true\n\tpartitioner.availability.timeout.ms = 0\n\tpartitioner.class = null\n\tpartitioner.ignore.keys = false\n\treceive.buffer.bytes = 32768\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.connect.timeout.ms = null\n\tsasl.login.read.timeout.ms = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.login.retry.backoff.max.ms = 10000\n\tsasl.login.retry.backoff.ms = 100\n\tsasl.mechanism = GSSAPI\n\tsasl.oauthbearer.clock.skew.seconds = 30\n\tsasl.oauthbearer.expected.audience = null\n\tsasl.oauthbearer.expected.issuer = null\n\tsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\n\tsasl.oauthbearer.jwks.endpoint.url = null\n\tsasl.oauthbearer.scope.claim.name = scope\n\tsasl.oauthbearer.sub.claim.name = sub\n\tsasl.oauthbearer.token.endpoint.url = null\n\tsecurity.protocol = PLAINTEXT\n\tsecurity.providers = null\n\tsend.buffer.bytes = 131072\n\tsocket.connection.setup.timeout.max.ms = 30000\n\tsocket.connection.setup.timeout.ms = 10000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.2\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttransaction.timeout.ms = 3600000\n\ttransactional.id = null\n\tvalue.serializer = class org.apache.flink.kafka.shaded.org.apache.kafka.common.serialization.ByteArraySerializer\n\n2024-04-10 23:01:21.254 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.KafkaProducer(596): [Producer clientId=producer-2] Instantiated an idempotent producer.\n2024-04-10 23:01:21.263 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.ProducerConfig(385): These configurations '[group.id]' were supplied but are not used yet.\n2024-04-10 23:01:21.265 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(119): Kafka version: 3.7.0\n2024-04-10 23:01:21.265 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(120): Kafka commitId: 2ae524ed625438c5\n2024-04-10 23:01:21.268 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(121): Kafka startTimeMs: 1712761281265\n2024-04-10 23:01:21.281 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator(598): Source Source: test[7] registering reader for parallel task 0 (#0) @ \n2024-04-10 23:01:21.281 INFO  org.apache.flink.runtime.taskmanager.Task(1085): Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1)#0 (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.\n2024-04-10 23:01:21.282 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator(384): Assigning splits to readers {0=[[Partition: test-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}\n2024-04-10 23:01:21.288 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph(1442): Source: test[7] -> test_kafka[8]: Writer -> test_kafka[8]: Committer (1/1) (a1f9559f9c54f2cf756b118e6dd29e5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.\n2024-04-10 23:01:21.290 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase(265): Adding split(s) to reader: [[Partition: test-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]\n2024-04-10 23:01:21.294 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.ConsumerConfig(376): ConsumerConfig values: \n\tallow.auto.create.topics = true\n\tauto.commit.interval.ms = 5000\n\tauto.include.jmx.reporter = true\n\tauto.offset.reset = earliest\n\tbootstrap.servers = [127.0.0.1:9092]\n\tcheck.crcs = true\n\tclient.dns.lookup = use_all_dns_ips\n\tclient.id = testGroup-0\n\tclient.rack = \n\tconnections.max.idle.ms = 540000\n\tdefault.api.timeout.ms = 60000\n\tenable.auto.commit = false\n\texclude.internal.topics = true\n\tfetch.max.bytes = 52428800\n\tfetch.max.wait.ms = 500\n\tfetch.min.bytes = 1\n\tgroup.id = testGroup\n\tgroup.instance.id = null\n\theartbeat.interval.ms = 3000\n\tinterceptor.classes = []\n\tinternal.leave.group.on.close = true\n\tinternal.throw.on.fetch.stable.offset.unsupported = false\n\tisolation.level = read_uncommitted\n\tkey.deserializer = class org.apache.flink.kafka.shaded.org.apache.kafka.common.serialization.ByteArrayDeserializer\n\tmax.partition.fetch.bytes = 1048576\n\tmax.poll.interval.ms = 300000\n\tmax.poll.records = 500\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartition.assignment.strategy = [class org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.CooperativeStickyAssignor]\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.connect.timeout.ms = null\n\tsasl.login.read.timeout.ms = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.login.retry.backoff.max.ms = 10000\n\tsasl.login.retry.backoff.ms = 100\n\tsasl.mechanism = GSSAPI\n\tsasl.oauthbearer.clock.skew.seconds = 30\n\tsasl.oauthbearer.expected.audience = null\n\tsasl.oauthbearer.expected.issuer = null\n\tsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\n\tsasl.oauthbearer.jwks.endpoint.url = null\n\tsasl.oauthbearer.scope.claim.name = scope\n\tsasl.oauthbearer.sub.claim.name = sub\n\tsasl.oauthbearer.token.endpoint.url = null\n\tsecurity.protocol = PLAINTEXT\n\tsecurity.providers = null\n\tsend.buffer.bytes = 131072\n\tsession.timeout.ms = 45000\n\tsocket.connection.setup.timeout.max.ms = 30000\n\tsocket.connection.setup.timeout.ms = 10000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.2\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\tvalue.deserializer = class org.apache.flink.kafka.shaded.org.apache.kafka.common.serialization.ByteArrayDeserializer\n\n2024-04-10 23:01:21.299 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.Metadata(287): [Producer clientId=producer-2] Cluster ID: 4ITBRX7KQhiCewPd219uAw\n2024-04-10 23:01:21.311 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.ConsumerConfig(385): These configurations '[client.id.prefix, partition.discovery.interval.ms]' were supplied but are not used yet.\n2024-04-10 23:01:21.311 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(119): Kafka version: 3.7.0\n2024-04-10 23:01:21.311 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(120): Kafka commitId: 2ae524ed625438c5\n2024-04-10 23:01:21.312 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(121): Kafka startTimeMs: 1712761281311\n2024-04-10 23:01:21.312 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.internals.TransactionManager(440): [Producer clientId=producer-2] ProducerId set to 8 with epoch 0\n2024-04-10 23:01:21.315 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher(115): Starting split fetcher 0\n2024-04-10 23:01:21.317 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.KafkaConsumer(1124): [Consumer clientId=testGroup-0, groupId=testGroup] Assigned to partition(s): test-0\n2024-04-10 23:01:21.318 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.internals.SubscriptionState(647): [Consumer clientId=testGroup-0, groupId=testGroup] Seeking to earliest offset of partition test-0\n2024-04-10 23:01:21.342 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.Metadata(402): [Consumer clientId=testGroup-0, groupId=testGroup] Resetting the last seen epoch of partition test-0 to 0 since the associated topicId changed from null to u16Uv8NXRsO485KT_fMEyA\n2024-04-10 23:01:21.343 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.Metadata(287): [Consumer clientId=testGroup-0, groupId=testGroup] Cluster ID: 4ITBRX7KQhiCewPd219uAw\n2024-04-10 23:01:21.355 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.consumer.internals.SubscriptionState(399): [Consumer clientId=testGroup-0, groupId=testGroup] Resetting offset for partition test-0 to position FetchPosition{offset=299167022, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.0.30:9092 (id: 0 rack: null)], epoch=0}}.\n2024-04-10 23:01:21.549 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.ProducerConfig(376): ProducerConfig values: \n\tacks = -1\n\tauto.include.jmx.reporter = true\n\tbatch.size = 16384\n\tbootstrap.servers = [127.0.0.1:9092]\n\tbuffer.memory = 33554432\n\tclient.dns.lookup = use_all_dns_ips\n\tclient.id = producer-3\n\tcompression.type = none\n\tconnections.max.idle.ms = 540000\n\tdelivery.timeout.ms = 120000\n\tenable.idempotence = true\n\tinterceptor.classes = []\n\tkey.serializer = class org.apache.flink.kafka.shaded.org.apache.kafka.common.serialization.ByteArraySerializer\n\tlinger.ms = 0\n\tmax.block.ms = 60000\n\tmax.in.flight.requests.per.connection = 5\n\tmax.request.size = 1048576\n\tmetadata.max.age.ms = 300000\n\tmetadata.max.idle.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartitioner.adaptive.partitioning.enable = true\n\tpartitioner.availability.timeout.ms = 0\n\tpartitioner.class = null\n\tpartitioner.ignore.keys = false\n\treceive.buffer.bytes = 32768\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretries = 2147483647\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.connect.timeout.ms = null\n\tsasl.login.read.timeout.ms = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.login.retry.backoff.max.ms = 10000\n\tsasl.login.retry.backoff.ms = 100\n\tsasl.mechanism = GSSAPI\n\tsasl.oauthbearer.clock.skew.seconds = 30\n\tsasl.oauthbearer.expected.audience = null\n\tsasl.oauthbearer.expected.issuer = null\n\tsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\n\tsasl.oauthbearer.jwks.endpoint.url = null\n\tsasl.oauthbearer.scope.claim.name = scope\n\tsasl.oauthbearer.sub.claim.name = sub\n\tsasl.oauthbearer.token.endpoint.url = null\n\tsecurity.protocol = PLAINTEXT\n\tsecurity.providers = null\n\tsend.buffer.bytes = 131072\n\tsocket.connection.setup.timeout.max.ms = 30000\n\tsocket.connection.setup.timeout.ms = 10000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.2\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttransaction.timeout.ms = 3600000\n\ttransactional.id = null\n\tvalue.serializer = class org.apache.flink.kafka.shaded.org.apache.kafka.common.serialization.ByteArraySerializer\n\n2024-04-10 23:01:21.552 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.KafkaProducer(596): [Producer clientId=producer-3] Instantiated an idempotent producer.\n2024-04-10 23:01:21.629 WARN  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.ProducerConfig(385): These configurations '[group.id]' were supplied but are not used yet.\n2024-04-10 23:01:21.631 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(119): Kafka version: 3.7.0\n2024-04-10 23:01:21.632 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(120): Kafka commitId: 2ae524ed625438c5\n2024-04-10 23:01:21.632 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(121): Kafka startTimeMs: 1712761281630\n2024-04-10 23:01:21.671 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.Metadata(402): [Producer clientId=producer-3] Resetting the last seen epoch of partition test_kafka-0 to 0 since the associated topicId changed from null to SkIw21tiSSuP5LzQGe7TMA\n2024-04-10 23:01:21.672 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.Metadata(287): [Producer clientId=producer-3] Cluster ID: 4ITBRX7KQhiCewPd219uAw\n2024-04-10 23:01:21.673 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.internals.TransactionManager(440): [Producer clientId=producer-3] ProducerId set to 9 with epoch 0\n2024-04-10 23:01:21.679 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.producer.KafkaProducer(1310): [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.\n2024-04-10 23:01:21.685 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics(693): Metrics scheduler closed\n2024-04-10 23:01:21.686 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics(697): Closing reporter org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.JmxReporter\n2024-04-10 23:01:21.687 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.metrics.Metrics(703): Metrics reporters closed\n2024-04-10 23:01:21.688 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.common.utils.AppInfoParser(83): App info kafka.producer for producer-3 unregistered\n2024-04-10 23:01:21.699 INFO  org.apache.flink.kafka.shaded.org.apache.kafka.clients.Metadata(402): [Producer clientId=producer-2] Resetting the last seen epoch of partition test_kafka-0 to 0 since the associated topicId changed from null to SkIw21tiSSuP5LzQGe7TMA\n2024-04-10 23:01:26.090 INFO  org.dinky.service.impl.TaskServiceImpl(192): execute job finished,status is SUCCESS\nProcess Step SUBMIT_EXECUTE exit with status:FINISHED\n2024-04-10 23:01:26.095 INFO  org.dinky.service.impl.TaskServiceImpl(323): Job Submit success\n","startTime":"2024-04-10 23:00:49.674","status":"FINISHED","time":36445,"title":"FlinkSubmit","type":"FLINK_SUBMIT"}